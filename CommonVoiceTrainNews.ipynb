{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24209,
     "status": "ok",
     "timestamp": 1619103323293,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "pbtczCi9nzm_",
    "outputId": "b2660202-49b6-41dc-86bb-1b237a1ddfa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 349280,
     "status": "ok",
     "timestamp": 1619103668367,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "sT-o1EJMovDl",
    "outputId": "08583db6-058d-4668-c75a-4de31faa9303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "/content/drive/My Drive/deepspeech\n",
      "Collecting pip==20.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 17.1MB/s \n",
      "\u001b[?25hCollecting wheel==0.34.2\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting setuptools==46.1.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
      "\u001b[K     |████████████████████████████████| 583kB 50.4MB/s \n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement wheel~=0.35, but you'll have wheel 0.34.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip, wheel, setuptools\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "  Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Found existing installation: setuptools 54.2.0\n",
      "    Uninstalling setuptools-54.2.0:\n",
      "      Successfully uninstalled setuptools-54.2.0\n",
      "Successfully installed pip-20.0.2 setuptools-46.1.3 wheel-0.34.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/drive/MyDrive/deepspeech\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 164 kB/s \n",
      "\u001b[?25hCollecting progressbar2\n",
      "  Downloading progressbar2-3.53.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pyxdg\n",
      "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 73.1 MB/s \n",
      "\u001b[?25hCollecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opuslib==2.0.0\n",
      "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-2.7.0-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 60.2 MB/s \n",
      "\u001b[?25hCollecting sox\n",
      "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 65.8 MB/s \n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 8.8 MB/s \n",
      "\u001b[?25hCollecting numba==0.47.0\n",
      "  Downloading numba-0.47.0-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 65.1 MB/s \n",
      "\u001b[?25hCollecting llvmlite==0.31.0\n",
      "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 74.1 MB/s \n",
      "\u001b[?25hCollecting soundfile\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting ds_ctcdecoder==0.7.4\n",
      "  Downloading ds_ctcdecoder-0.7.4-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 57.1 MB/s \n",
      "\u001b[?25hCollecting tensorflow==1.15.2\n",
      "  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 110.5 MB 14 kB/s \n",
      "\u001b[?25hCollecting python-utils>=2.3.0\n",
      "  Downloading python_utils-2.5.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 6.7 MB/s \n",
      "\u001b[?25hCollecting scipy!=1.4.0\n",
      "  Downloading scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4 MB 66 kB/s \n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.5.8-py2.py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 77.0 MB/s \n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 4.9 MB/s \n",
      "\u001b[?25hCollecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.11-cp37-cp37m-manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 63.4 MB/s \n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.7.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 9.8 MB/s \n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 78.9 MB/s \n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 69.0 MB/s \n",
      "\u001b[?25hCollecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 42.0 MB/s \n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 7.6 MB/s \n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 79.5 MB/s \n",
      "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 71.1 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 69.4 MB/s \n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading setuptools-56.0.0-py3-none-any.whl (784 kB)\n",
      "\u001b[K     |████████████████████████████████| 784 kB 63.2 MB/s \n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 65.6 MB/s \n",
      "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0\n",
      "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 1.5 MB/s \n",
      "\u001b[?25hCollecting joblib>=0.14\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 69.1 MB/s \n",
      "\u001b[?25hCollecting decorator>=3.0.0\n",
      "  Downloading decorator-5.0.7-py3-none-any.whl (8.8 kB)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "\u001b[K     |████████████████████████████████| 323 kB 76.4 MB/s \n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 431 kB/s \n",
      "\u001b[?25hCollecting cffi>=1.0\n",
      "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "\u001b[K     |████████████████████████████████| 402 kB 71.0 MB/s \n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 64.6 MB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.37.0-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 69.7 MB/s \n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 65.1 MB/s \n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.6 MB/s \n",
      "\u001b[?25hCollecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 8.6 MB/s \n",
      "\u001b[?25hCollecting wheel>=0.26; python_version >= \"3\"\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 59.1 MB/s \n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.6 MB/s \n",
      "\u001b[?25hCollecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.3 MB/s \n",
      "\u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting greenlet!=0.4.17; python_version >= \"3\"\n",
      "  Downloading greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 65.6 MB/s \n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 75.4 MB/s \n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 6.3 MB/s \n",
      "\u001b[?25hCollecting PyYAML>=3.12\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 73.5 MB/s \n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-1.5.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 68.2 MB/s \n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 74.6 MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 70.5 MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 7.8 MB/s \n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 74.6 MB/s \n",
      "\u001b[?25hCollecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting attrs>=16.3.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 7.0 MB/s \n",
      "\u001b[?25hCollecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: opuslib, bs4, librosa, audioread, resampy, wrapt, termcolor, gast, pyperclip\n",
      "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=ab0497e7f69a8c3888f5b5db7ae6f8ae5196422d0a0070da764180a2e37d4a45\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/ba/d4/0e81231a9797fbb262ae3a54fd761fab850db7f32d94a3283a\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=8eb1e49907ef8210a0afea8d8828ab14faa419aa37c143aafb464973fd94f037\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201374 sha256=c4083f045f791f127847700c9180a4fd8d26a14e16244f4ed054f07776fc43ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23142 sha256=55760515bceff782a67da511992d978f829a6789039415a8e17f69268463d351\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/7b/eb/213741ccc0678f63e346ab8dff10495995ca3f426af87b8d88\n",
      "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320720 sha256=c258457a0728d82b7ce518647b6e1793a8dc46efe206d51487ab6fc1181d590f\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/18/0a/8ad18a597d8333a142c9789338a96a6208f1198d290ece356c\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68662 sha256=dc329f0176ed824e9368d95da5ba54247e8a19476fe12a81ff7b3b9b976a3695\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=3179c4b203f8e3656a91c6e0c2cd6b35b4a143e74317ddf13aecb4a5a5a90bb8\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=ef6b3b69dcb3ad42e57088b8ee3ca5daae75ab0ea8e81f5676a8b86343ced820\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=98adb1108e2a0fcb2d28cb97630344f9076f2d70162cb8d44d3ecc9eaf320525\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built opuslib bs4 librosa audioread resampy wrapt termcolor gast pyperclip\n",
      "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: networkx 2.5.1 has requirement decorator<5,>=4.3, but you'll have decorator 5.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: moviepy 0.2.3.5 has requirement decorator<5.0,>=4.0.2, but you'll have decorator 5.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, six, python-utils, progressbar2, pyxdg, attrdict, absl-py, semver, opuslib, pyparsing, packaging, scipy, zipp, typing-extensions, importlib-metadata, greenlet, sqlalchemy, python-editor, python-dateutil, MarkupSafe, Mako, alembic, cmaes, tqdm, colorlog, pbr, stevedore, PyYAML, wcwidth, PrettyTable, colorama, attrs, pyperclip, cmd2, cliff, optuna, sox, soupsieve, beautifulsoup4, bs4, pytz, pandas, idna, certifi, chardet, urllib3, requests, setuptools, llvmlite, numba, audioread, threadpoolctl, joblib, scikit-learn, decorator, resampy, pycparser, cffi, soundfile, appdirs, pooch, librosa, ds-ctcdecoder, astor, protobuf, grpcio, werkzeug, wheel, markdown, tensorboard, google-pasta, cached-property, h5py, keras-applications, wrapt, tensorflow-estimator, termcolor, gast, keras-preprocessing, opt-einsum, tensorflow, deepspeech-training\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: python-utils\n",
      "    Found existing installation: python-utils 2.5.6\n",
      "    Uninstalling python-utils-2.5.6:\n",
      "      Successfully uninstalled python-utils-2.5.6\n",
      "  Attempting uninstall: progressbar2\n",
      "    Found existing installation: progressbar2 3.38.0\n",
      "    Uninstalling progressbar2-3.38.0:\n",
      "      Successfully uninstalled progressbar2-3.38.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.1\n",
      "    Uninstalling importlib-metadata-3.10.1:\n",
      "      Successfully uninstalled importlib-metadata-3.10.1\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 1.0.0\n",
      "    Uninstalling greenlet-1.0.0:\n",
      "      Successfully uninstalled greenlet-1.0.0\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.7\n",
      "    Uninstalling SQLAlchemy-1.4.7:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.7\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: PrettyTable\n",
      "    Found existing installation: prettytable 2.1.0\n",
      "    Uninstalling prettytable-2.1.0:\n",
      "      Successfully uninstalled prettytable-2.1.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.3.0\n",
      "    Uninstalling attrs-20.3.0:\n",
      "      Successfully uninstalled attrs-20.3.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "  Attempting uninstall: bs4\n",
      "    Found existing installation: bs4 0.0.1\n",
      "    Uninstalling bs4-0.0.1:\n",
      "      Successfully uninstalled bs4-0.0.1\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.12.5\n",
      "    Uninstalling certifi-2020.12.5:\n",
      "      Successfully uninstalled certifi-2020.12.5\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 46.1.3\n",
      "    Uninstalling setuptools-46.1.3:\n",
      "      Successfully uninstalled setuptools-46.1.3\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.34.0\n",
      "    Uninstalling llvmlite-0.34.0:\n",
      "      Successfully uninstalled llvmlite-0.34.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.51.2\n",
      "    Uninstalling numba-0.51.2:\n",
      "      Successfully uninstalled numba-0.51.2\n",
      "  Attempting uninstall: audioread\n",
      "    Found existing installation: audioread 2.1.9\n",
      "    Uninstalling audioread-2.1.9:\n",
      "      Successfully uninstalled audioread-2.1.9\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: resampy\n",
      "    Found existing installation: resampy 0.2.2\n",
      "    Uninstalling resampy-0.2.2:\n",
      "      Successfully uninstalled resampy-0.2.2\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.5\n",
      "    Uninstalling cffi-1.14.5:\n",
      "      Successfully uninstalled cffi-1.14.5\n",
      "  Attempting uninstall: soundfile\n",
      "    Found existing installation: SoundFile 0.10.3.post1\n",
      "    Uninstalling SoundFile-0.10.3.post1:\n",
      "      Successfully uninstalled SoundFile-0.10.3.post1\n",
      "  Attempting uninstall: appdirs\n",
      "    Found existing installation: appdirs 1.4.4\n",
      "    Uninstalling appdirs-1.4.4:\n",
      "      Successfully uninstalled appdirs-1.4.4\n",
      "  Attempting uninstall: pooch\n",
      "    Found existing installation: pooch 1.3.0\n",
      "    Uninstalling pooch-1.3.0:\n",
      "      Successfully uninstalled pooch-1.3.0\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.8.0\n",
      "    Uninstalling librosa-0.8.0:\n",
      "      Successfully uninstalled librosa-0.8.0\n",
      "  Attempting uninstall: astor\n",
      "    Found existing installation: astor 0.8.1\n",
      "    Uninstalling astor-0.8.1:\n",
      "      Successfully uninstalled astor-0.8.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.4\n",
      "    Uninstalling protobuf-3.12.4:\n",
      "      Successfully uninstalled protobuf-3.12.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.3.4\n",
      "    Uninstalling Markdown-3.3.4:\n",
      "      Successfully uninstalled Markdown-3.3.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "  Running setup.py develop for deepspeech-training\n",
      "Successfully installed Mako-1.1.4 MarkupSafe-1.1.1 PrettyTable-2.1.0 PyYAML-5.4.1 absl-py-0.12.0 alembic-1.5.8 appdirs-1.4.4 astor-0.8.1 attrdict-2.0.1 attrs-20.3.0 audioread-2.1.9 beautifulsoup4-4.9.3 bs4-0.0.1 cached-property-1.5.2 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 decorator-5.0.7 deepspeech-training ds-ctcdecoder-0.7.4 gast-0.2.2 google-pasta-0.2.0 greenlet-1.0.0 grpcio-1.37.0 h5py-3.2.1 idna-2.10 importlib-metadata-4.0.1 joblib-1.0.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 librosa-0.8.0 llvmlite-0.31.0 markdown-3.3.4 numba-0.47.0 numpy-1.20.2 opt-einsum-3.3.0 optuna-2.7.0 opuslib-2.0.0 packaging-20.9 pandas-1.2.4 pbr-5.5.1 pooch-1.3.0 progressbar2-3.53.1 protobuf-3.15.8 pycparser-2.20 pyparsing-2.4.7 pyperclip-1.8.2 python-dateutil-2.8.1 python-editor-1.0.4 python-utils-2.5.6 pytz-2021.1 pyxdg-0.27 requests-2.25.1 resampy-0.2.2 scikit-learn-0.24.1 scipy-1.6.2 semver-2.13.0 setuptools-56.0.0 six-1.15.0 soundfile-0.10.3.post1 soupsieve-2.2.1 sox-1.4.1 sqlalchemy-1.4.11 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0 threadpoolctl-2.1.0 tqdm-4.60.0 typing-extensions-3.7.4.3 urllib3-1.26.4 wcwidth-0.2.5 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "astor",
         "cffi",
         "dateutil",
         "decorator",
         "google",
         "numpy",
         "pandas",
         "pkg_resources",
         "pyparsing",
         "pytz",
         "six",
         "wcwidth"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: /content/drive/MyDrive/deepspeech/tc/native_client.tar.xz\n",
      "libdeepspeech.so\n",
      "LICENSE\n",
      "deepspeech\n",
      "deepspeech.h\n",
      "README.mozilla\n",
      "Found existing installation: protobuf 3.15.8\n",
      "Uninstalling protobuf-3.15.8:\n",
      "  Successfully uninstalled protobuf-3.15.8\n",
      "Collecting protobuf==3.8\n",
      "  Downloading protobuf-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 19.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (56.0.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (1.15.0)\n",
      "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-api-core 1.26.3 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-3.8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 1.15.2\n",
      "Uninstalling tensorflow-1.15.2:\n",
      "  Successfully uninstalled tensorflow-1.15.2\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "TensorFlow 1.x selected.\n",
      "Collecting tensorflow-gpu==1.15.2\n",
      "  Downloading tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.9 MB 33 kB/s \n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.20.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.12.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.37.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2) (56.0.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.4)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (1.5.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.7.4.3)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.15.2\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3\n",
    "!pip3 install --upgrade --force-reinstall -e .\n",
    "!python util/taskcluster.py --arch gpu --target tc/ --branch v0.7.4\n",
    "\n",
    "!pip uninstall -y protobuf\n",
    "!pip install protobuf==3.8\n",
    "\n",
    "!pip uninstall -y tensorflow\n",
    "!pip uninstall -y tensorflow-gpu\n",
    "%tensorflow_version 1.x\n",
    "!pip install tensorflow-gpu==1.15.2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347487,
     "status": "ok",
     "timestamp": 1619103668368,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "n7wnz0EBoy33",
    "outputId": "d2659ec0-f5e7-452d-a768-10de226f94fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 347532,
     "status": "ok",
     "timestamp": 1619103669704,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "8SBrWluio2YH"
   },
   "outputs": [],
   "source": [
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/lmplz'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/build_binary'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/filter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5615,
     "status": "ok",
     "timestamp": 1619103775969,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "tKnIAIpPqCus",
    "outputId": "b8375595-72da-4741-fba4-d6f97e141285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |                   #                            | 22546 Elapsed Time: 0:00:01\n",
      "\n",
      "Saving top 45426 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 166345 words in total\n",
      "  It has 45426 unique words\n",
      "  Your top-45426 words are 100.0000 percent of all words\n",
      "  Your most common word \"என்று\" occurred 1135 times\n",
      "  The least common word in your top-k is \"வேலைச்\" with 1 times\n",
      "  The first word with 2 occurrences is \"வழங்குவோம்\" at place 20985\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x55705f3a0000 @  0x7f989a1fd1e7 0x55705d05e772 0x55705cff2358 0x55705cfd1290 0x55705cfbd096 0x7f9898396bf7 0x55705cfbeada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x5570fe838000 @  0x7f989a1fd1e7 0x55705d05e772 0x55705d0487aa 0x55705d0491c8 0x55705cfd12ad 0x55705cfbd096 0x7f9898396bf7 0x55705cfbeada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 166345 types 45429\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:545148 2:4036518912 3:7568473088\n",
      "tcmalloc: large alloc 7568474112 bytes == 0x55705f292000 @  0x7f989a1fd1e7 0x55705d05e772 0x55705d0487aa 0x55705d0491c8 0x55705cfd184e 0x55705cfbd096 0x7f9898396bf7 0x55705cfbeada\n",
      "tcmalloc: large alloc 4036526080 bytes == 0x557312014000 @  0x7f989a1fd1e7 0x55705d05e772 0x55705d0487aa 0x55705d0491c8 0x55705cfd1c3d 0x55705cfbd096 0x7f9898396bf7 0x55705cfbeada\n",
      "Statistics:\n",
      "1 45429 D1=0.74119 D2=1.11499 D3+=1.33513\n",
      "2 123424 D1=0.868584 D2=1.20845 D3+=1.67973\n",
      "3 19501/136612 D1=0.807534 D2=1.24958 D3+=2.66451\n",
      "Memory estimate for binary LM:\n",
      "type      kB\n",
      "probing 4389 assuming -p 1.5\n",
      "probing 5289 assuming -r models -p 1.5\n",
      "trie    2592 without quantization\n",
      "trie    1833 assuming -q 8 -b 8 quantization \n",
      "trie    2431 assuming -a 22 array pointer compression\n",
      "trie    1671 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:545148 2:1974784 3:390020\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "###***********######################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:545148 2:1974784 3:390020\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15538212 kB\tVmRSS:2642056 kB\tRSSMax:2656336 kB\tuser:0.430062\tsys:1.15317\tCPU:1.58329\treal:1.75607\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamil/News_CommonVoiceTrain.txt' --output_dir . \\\n",
    "  --top_k 45426 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4145,
     "status": "ok",
     "timestamp": 1619103784383,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "aby2ppleqCxp",
    "outputId": "3568a79c-6224-4e44-cd02-c0df7bbae81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "45426 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-45426.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433389,
     "status": "ok",
     "timestamp": 1619104226651,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "KASUZOS23hrL",
    "outputId": "2cda4c8a-16e3-42db-e15b-0a3908af1780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-22 15:03:18.686985: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-22 15:03:18.687349: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559351d3b480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 15:03:18.687397: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 15:03:18.693450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 15:03:18.882992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:18.883757: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55935571e1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 15:03:18.883792: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-04-22 15:03:18.884793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:18.885330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-22 15:03:18.897552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-22 15:03:19.141294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-22 15:03:19.288508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-22 15:03:19.306148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-22 15:03:19.586846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-22 15:03:19.601952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-22 15:03:20.101055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-22 15:03:20.101251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:20.101946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:20.102463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-22 15:03:20.105687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-22 15:03:20.107706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-22 15:03:20.107751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-22 15:03:20.107764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-22 15:03:20.108604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:20.109265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:20.109877: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-22 15:03:20.109925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I0422 15:03:21.344997 140549794744192 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "2021-04-22 15:03:23.110747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:23.111364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-22 15:03:23.111435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-22 15:03:23.111458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-22 15:03:23.111481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-22 15:03:23.111503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-22 15:03:23.111527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-22 15:03:23.111547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-22 15:03:23.111566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-22 15:03:23.111654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:23.112235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:23.112752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-22 15:03:23.112797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-22 15:03:23.112812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-22 15:03:23.112821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-22 15:03:23.112911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:23.113445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-22 15:03:23.113987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I Loading best validating checkpoint from /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4290\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "Test epoch | Steps: 0 | Elapsed Time: 0:00:00                                   2021-04-22 15:03:34.827336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-22 15:03:48.522696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:06:49                                  \n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.269946, CER: 0.124540, loss: 28.758253\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 73.912682\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19523139.wav\n",
      " - src: \"கற்க கசடறக் கற்பவை கற்றபின் நிற்க அதற்குத் தக \"\n",
      " - res: \"கற்க கசடறக் கற்பவை கற்றபின் நிற்க அதற்குத் தக \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 73.304062\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21302859.wav\n",
      " - src: \"நன்றி மறப்பது நன்றன்று நன்றல்லது அன்றே மறப்பது நன்று \"\n",
      " - res: \"நன்றி மறப்பது நன்றன்று நன்றல்லது அன்றே மறப்பது நன்று \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 67.433968\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20593143.wav\n",
      " - src: \"செல்வத்துள் செல்வம் செவிச்செல்வம் அச்செல்வம் செல்வத்துளெல்லாந் தலை \"\n",
      " - res: \"செல்வத்துள் செல்வம் செவிச்செல்வம் அச்செல்வம் செல்வத்துளெல்லாந் தலை \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 67.215149\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19183354.wav\n",
      " - src: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      " - res: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 66.839272\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21354529.wav\n",
      " - src: \"நிறையுடைமை நீங்காமை வேண்டின் பொறையுடைமை போற்றியொழுகப்படும் \"\n",
      " - res: \"நிறையுடைமை நீங்காமை வேண்டின் பொறையுடைமை போற்றியொழுகப்படும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.888446\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20394649.wav\n",
      " - src: \"இன்பம் அனைத்திலும் துன்பங்கள் சேர்ந்தன \"\n",
      " - res: \"இன்பம் அனைத்திலும் துன்பங்கள் சேர்ந்தன \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.032258, loss: 9.803870\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21291351.wav\n",
      " - src: \"தலைவியும் பையனும் தலைவர் தாமும்\"\n",
      " - res: \"தலைவியும் பையனும் தலைவர் தாமும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.029412, loss: 9.801140\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21380538.wav\n",
      " - src: \"இதம்அகிதம் தெரியாமல் உம்மை நாங்கள்\"\n",
      " - res: \"இதம்அகிதம் தெரியாமல் உம்மை நாங்கள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.798675\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21348504.wav\n",
      " - src: \"மனம்பொருந் தாமணம் மண்ணாய்ப் போக \"\n",
      " - res: \"மனம்பொருந் தாமணம் மண்ணாய்ப் போக \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.032258, loss: 9.717348\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19093634.wav\n",
      " - src: \"தாயுள்ளம் தனிலன்றோ இன்பம் ஆங்கே\"\n",
      " - res: \"தாயுள்ளம் தனிலன்றோ இன்பம் ஆங்கே \"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.320000, loss: 22.328712\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19523104.wav\n",
      " - src: \"மக்களெல்லாம் ஒப்புடையார் \"\n",
      " - res: \"மக்களெல் லாம்துணை யார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.388889, loss: 18.650330\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19083934.wav\n",
      " - src: \"சமுகத்தை நொந்தான் \"\n",
      " - res: \"சமூக கத்தை குண்டான் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.400000, loss: 14.939497\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21277402.wav\n",
      " - src: \"தொல்லை தரும்புவியில்\"\n",
      " - res: \"கொள்ளை தரும் பொறியல் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.666667, CER: 0.177778, loss: 26.557951\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395015.wav\n",
      " - src: \"உளம்துடித்தார் எனினும்அவர் உயிர்வாழ்கின்றார் \"\n",
      " - res: \"கலங்கடித்தான் எனினும் அவர் உயிர் வாழ்கின்றார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.416667, loss: 30.154238\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_22435893.wav\n",
      " - src: \"ஃபயர்ஃபாக்ஸ்\"\n",
      " - res: \"பயன் பாக்கி\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --test_output_file '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/NewsArticles/Output/newsarticles.json' \\\n",
    "  --checkpoint_dir '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\\n",
    "  \"$@\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPQVuxIm0J/hMHbUtZgm3mD",
   "collapsed_sections": [],
   "name": "NewsArticles.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
