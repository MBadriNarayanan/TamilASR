{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31670,
     "status": "ok",
     "timestamp": 1619102256364,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "p4VDSM0gn01t",
    "outputId": "495cb830-2be9-4ec7-9499-018cb6699586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 386269,
     "status": "ok",
     "timestamp": 1619102656233,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "bj6Pi52goTFj",
    "outputId": "130035cb-b585-4079-f1a3-12056102b232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "/content/drive/My Drive/deepspeech\n",
      "Collecting pip==20.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 5.5MB/s \n",
      "\u001b[?25hCollecting wheel==0.34.2\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting setuptools==46.1.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
      "\u001b[K     |████████████████████████████████| 583kB 35.2MB/s \n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement wheel~=0.35, but you'll have wheel 0.34.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip, wheel, setuptools\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "  Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Found existing installation: setuptools 54.2.0\n",
      "    Uninstalling setuptools-54.2.0:\n",
      "      Successfully uninstalled setuptools-54.2.0\n",
      "Successfully installed pip-20.0.2 setuptools-46.1.3 wheel-0.34.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/drive/My%20Drive/deepspeech\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 247 kB/s \n",
      "\u001b[?25hCollecting progressbar2\n",
      "  Downloading progressbar2-3.53.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pyxdg\n",
      "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 52.8 MB/s \n",
      "\u001b[?25hCollecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opuslib==2.0.0\n",
      "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-2.7.0-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 53.8 MB/s \n",
      "\u001b[?25hCollecting sox\n",
      "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 52.4 MB/s \n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 6.7 MB/s \n",
      "\u001b[?25hCollecting numba==0.47.0\n",
      "  Downloading numba-0.47.0-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 42.1 MB/s \n",
      "\u001b[?25hCollecting llvmlite==0.31.0\n",
      "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 39.1 MB/s \n",
      "\u001b[?25hCollecting soundfile\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting ds_ctcdecoder==0.7.4\n",
      "  Downloading ds_ctcdecoder-0.7.4-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 48.2 MB/s \n",
      "\u001b[?25hCollecting tensorflow==1.15.2\n",
      "  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 110.5 MB 30 kB/s \n",
      "\u001b[?25hCollecting python-utils>=2.3.0\n",
      "  Downloading python_utils-2.5.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.7.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 6.3 MB/s \n",
      "\u001b[?25hCollecting scipy!=1.4.0\n",
      "  Downloading scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4 MB 133 kB/s \n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.5.8-py2.py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 3.5 MB/s \n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.11-cp37-cp37m-manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 52.7 MB/s \n",
      "\u001b[?25hCollecting packaging>=20.0\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 3.9 MB/s \n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 47.4 MB/s \n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 60.5 MB/s \n",
      "\u001b[?25hCollecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 59.9 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 69.8 MB/s \n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 75.6 MB/s \n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 5.1 MB/s \n",
      "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 49.3 MB/s \n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading setuptools-56.0.0-py3-none-any.whl (784 kB)\n",
      "\u001b[K     |████████████████████████████████| 784 kB 38.5 MB/s \n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 71.4 MB/s \n",
      "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0\n",
      "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 1.5 MB/s \n",
      "\u001b[?25hCollecting joblib>=0.14\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 59.1 MB/s \n",
      "\u001b[?25hCollecting decorator>=3.0.0\n",
      "  Downloading decorator-5.0.7-py3-none-any.whl (8.8 kB)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "\u001b[K     |████████████████████████████████| 323 kB 54.1 MB/s \n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 317 kB/s \n",
      "\u001b[?25hCollecting cffi>=1.0\n",
      "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "\u001b[K     |████████████████████████████████| 402 kB 57.8 MB/s \n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 56.1 MB/s \n",
      "\u001b[?25hCollecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 2.8 MB/s \n",
      "\u001b[?25hCollecting wheel>=0.26; python_version >= \"3\"\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 50.9 MB/s \n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.37.0-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 37.9 MB/s \n",
      "\u001b[?25hCollecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 40.9 MB/s \n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.8 MB/s \n",
      "\u001b[?25hCollecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 5.3 MB/s \n",
      "\u001b[?25hCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 895 kB/s \n",
      "\u001b[?25hCollecting pyparsing>=2.1.0\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 4.9 MB/s \n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-1.5.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 52.1 MB/s \n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 49.2 MB/s \n",
      "\u001b[?25hCollecting PyYAML>=3.12\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 56.5 MB/s \n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.6 MB/s \n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 3.0 MB/s \n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting greenlet!=0.4.17; python_version >= \"3\"\n",
      "  Downloading greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 39.5 MB/s \n",
      "\u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 70.1 MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 5.3 MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 58.7 MB/s \n",
      "\u001b[?25hCollecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting wcwidth>=0.1.7\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Collecting attrs>=16.3.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.1 MB/s \n",
      "\u001b[?25hCollecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: opuslib, bs4, librosa, audioread, resampy, gast, termcolor, wrapt, pyperclip\n",
      "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=0205671b8ca95a504943a43a46af40a385636be914ea84078ddc7631b536a716\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/ba/d4/0e81231a9797fbb262ae3a54fd761fab850db7f32d94a3283a\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=22611a63d4c1df58e11a76a37e86041269a0a3dd23ca3185d111912d79231981\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201374 sha256=f950e1febd24eb9906b3271c22a94ae5bff9031b6e34ad107e01aae194cec9cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23142 sha256=3847eb2007623b68b16ddb004d391b2a1caf4628560821a5be824f3dea69704d\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/7b/eb/213741ccc0678f63e346ab8dff10495995ca3f426af87b8d88\n",
      "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320720 sha256=afe987ac696a1f5350a799c5d1ae0c0ddc30532accb7e3fa4a7a0ea10daf6cf4\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/18/0a/8ad18a597d8333a142c9789338a96a6208f1198d290ece356c\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=626d39a9edf119f5560b3a3b0a4b969c3f37307e6bf3a57c1aba158444bb6e02\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=e9dbf20dbc91dfbbad9fde1e1770a0a4d58991cbfbe47443045000f81fcc692f\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68665 sha256=2ca379cd86920c659612c519fc48ab6283f8a4c72a4208f9cd2ba1c37aa9eec4\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=3b44be6c03d051f1cacc2dc0118da773748c858cdfa121f5aa7f49f946988799\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built opuslib bs4 librosa audioread resampy gast termcolor wrapt pyperclip\n",
      "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: networkx 2.5.1 has requirement decorator<5,>=4.3, but you'll have decorator 5.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: moviepy 0.2.3.5 has requirement decorator<5.0,>=4.0.2, but you'll have decorator 5.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, six, python-utils, progressbar2, pyxdg, attrdict, absl-py, semver, opuslib, pyparsing, colorama, wcwidth, zipp, typing-extensions, importlib-metadata, pyperclip, attrs, cmd2, pbr, PyYAML, PrettyTable, stevedore, cliff, scipy, cmaes, python-dateutil, MarkupSafe, Mako, greenlet, sqlalchemy, python-editor, alembic, tqdm, colorlog, packaging, optuna, sox, soupsieve, beautifulsoup4, bs4, pytz, pandas, urllib3, certifi, idna, chardet, requests, llvmlite, setuptools, numba, audioread, threadpoolctl, joblib, scikit-learn, decorator, resampy, pycparser, cffi, soundfile, appdirs, pooch, librosa, ds-ctcdecoder, astor, tensorflow-estimator, gast, opt-einsum, wheel, grpcio, markdown, werkzeug, protobuf, tensorboard, termcolor, google-pasta, cached-property, h5py, keras-applications, wrapt, keras-preprocessing, tensorflow, deepspeech-training\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: python-utils\n",
      "    Found existing installation: python-utils 2.5.6\n",
      "    Uninstalling python-utils-2.5.6:\n",
      "      Successfully uninstalled python-utils-2.5.6\n",
      "  Attempting uninstall: progressbar2\n",
      "    Found existing installation: progressbar2 3.38.0\n",
      "    Uninstalling progressbar2-3.38.0:\n",
      "      Successfully uninstalled progressbar2-3.38.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.1\n",
      "    Uninstalling importlib-metadata-3.10.1:\n",
      "      Successfully uninstalled importlib-metadata-3.10.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.3.0\n",
      "    Uninstalling attrs-20.3.0:\n",
      "      Successfully uninstalled attrs-20.3.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: PrettyTable\n",
      "    Found existing installation: prettytable 2.1.0\n",
      "    Uninstalling prettytable-2.1.0:\n",
      "      Successfully uninstalled prettytable-2.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 1.0.0\n",
      "    Uninstalling greenlet-1.0.0:\n",
      "      Successfully uninstalled greenlet-1.0.0\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.7\n",
      "    Uninstalling SQLAlchemy-1.4.7:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.7\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "  Attempting uninstall: bs4\n",
      "    Found existing installation: bs4 0.0.1\n",
      "    Uninstalling bs4-0.0.1:\n",
      "      Successfully uninstalled bs4-0.0.1\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.12.5\n",
      "    Uninstalling certifi-2020.12.5:\n",
      "      Successfully uninstalled certifi-2020.12.5\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.34.0\n",
      "    Uninstalling llvmlite-0.34.0:\n",
      "      Successfully uninstalled llvmlite-0.34.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 46.1.3\n",
      "    Uninstalling setuptools-46.1.3:\n",
      "      Successfully uninstalled setuptools-46.1.3\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.51.2\n",
      "    Uninstalling numba-0.51.2:\n",
      "      Successfully uninstalled numba-0.51.2\n",
      "  Attempting uninstall: audioread\n",
      "    Found existing installation: audioread 2.1.9\n",
      "    Uninstalling audioread-2.1.9:\n",
      "      Successfully uninstalled audioread-2.1.9\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: resampy\n",
      "    Found existing installation: resampy 0.2.2\n",
      "    Uninstalling resampy-0.2.2:\n",
      "      Successfully uninstalled resampy-0.2.2\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.5\n",
      "    Uninstalling cffi-1.14.5:\n",
      "      Successfully uninstalled cffi-1.14.5\n",
      "  Attempting uninstall: soundfile\n",
      "    Found existing installation: SoundFile 0.10.3.post1\n",
      "    Uninstalling SoundFile-0.10.3.post1:\n",
      "      Successfully uninstalled SoundFile-0.10.3.post1\n",
      "  Attempting uninstall: appdirs\n",
      "    Found existing installation: appdirs 1.4.4\n",
      "    Uninstalling appdirs-1.4.4:\n",
      "      Successfully uninstalled appdirs-1.4.4\n",
      "  Attempting uninstall: pooch\n",
      "    Found existing installation: pooch 1.3.0\n",
      "    Uninstalling pooch-1.3.0:\n",
      "      Successfully uninstalled pooch-1.3.0\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.8.0\n",
      "    Uninstalling librosa-0.8.0:\n",
      "      Successfully uninstalled librosa-0.8.0\n",
      "  Attempting uninstall: astor\n",
      "    Found existing installation: astor 0.8.1\n",
      "    Uninstalling astor-0.8.1:\n",
      "      Successfully uninstalled astor-0.8.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.3.4\n",
      "    Uninstalling Markdown-3.3.4:\n",
      "      Successfully uninstalled Markdown-3.3.4\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.4\n",
      "    Uninstalling protobuf-3.12.4:\n",
      "      Successfully uninstalled protobuf-3.12.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "  Running setup.py develop for deepspeech-training\n",
      "Successfully installed Mako-1.1.4 MarkupSafe-1.1.1 PrettyTable-2.1.0 PyYAML-5.4.1 absl-py-0.12.0 alembic-1.5.8 appdirs-1.4.4 astor-0.8.1 attrdict-2.0.1 attrs-20.3.0 audioread-2.1.9 beautifulsoup4-4.9.3 bs4-0.0.1 cached-property-1.5.2 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 decorator-5.0.7 deepspeech-training ds-ctcdecoder-0.7.4 gast-0.2.2 google-pasta-0.2.0 greenlet-1.0.0 grpcio-1.37.0 h5py-3.2.1 idna-2.10 importlib-metadata-4.0.1 joblib-1.0.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 librosa-0.8.0 llvmlite-0.31.0 markdown-3.3.4 numba-0.47.0 numpy-1.20.2 opt-einsum-3.3.0 optuna-2.7.0 opuslib-2.0.0 packaging-20.9 pandas-1.2.4 pbr-5.5.1 pooch-1.3.0 progressbar2-3.53.1 protobuf-3.15.8 pycparser-2.20 pyparsing-2.4.7 pyperclip-1.8.2 python-dateutil-2.8.1 python-editor-1.0.4 python-utils-2.5.6 pytz-2021.1 pyxdg-0.27 requests-2.25.1 resampy-0.2.2 scikit-learn-0.24.1 scipy-1.6.2 semver-2.13.0 setuptools-56.0.0 six-1.15.0 soundfile-0.10.3.post1 soupsieve-2.2.1 sox-1.4.1 sqlalchemy-1.4.11 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0 threadpoolctl-2.1.0 tqdm-4.60.0 typing-extensions-3.7.4.3 urllib3-1.26.4 wcwidth-0.2.5 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "astor",
         "cffi",
         "dateutil",
         "decorator",
         "google",
         "numpy",
         "pandas",
         "pkg_resources",
         "pyparsing",
         "pytz",
         "six",
         "wcwidth"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: /content/drive/My Drive/deepspeech/tc/native_client.tar.xz\n",
      "libdeepspeech.so\n",
      "LICENSE\n",
      "deepspeech\n",
      "deepspeech.h\n",
      "README.mozilla\n",
      "Found existing installation: protobuf 3.15.8\n",
      "Uninstalling protobuf-3.15.8:\n",
      "  Successfully uninstalled protobuf-3.15.8\n",
      "Collecting protobuf==3.8\n",
      "  Downloading protobuf-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (56.0.0)\n",
      "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-api-core 1.26.3 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-3.8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 1.15.2\n",
      "Uninstalling tensorflow-1.15.2:\n",
      "  Successfully uninstalled tensorflow-1.15.2\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "TensorFlow 1.x selected.\n",
      "Collecting tensorflow-gpu==1.15.2\n",
      "  Downloading tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.9 MB 32 kB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.12.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.20.2)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.37.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.36.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (56.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.0.1)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.1)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.15.2\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3\n",
    "!pip3 install --upgrade --force-reinstall -e .\n",
    "!python util/taskcluster.py --arch gpu --target tc/ --branch v0.7.4\n",
    "\n",
    "!pip uninstall -y protobuf\n",
    "!pip install protobuf==3.8\n",
    "\n",
    "!pip uninstall -y tensorflow\n",
    "!pip uninstall -y tensorflow-gpu\n",
    "%tensorflow_version 1.x\n",
    "!pip install tensorflow-gpu==1.15.2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384893,
     "status": "ok",
     "timestamp": 1619102656234,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "6LMUFyKhoTIE",
    "outputId": "0e4a0df6-9f32-4a33-c355-b46c1b172883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 385478,
     "status": "ok",
     "timestamp": 1619102657107,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "loOROWVvo1ZY"
   },
   "outputs": [],
   "source": [
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/lmplz'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/build_binary'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/filter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282463,
     "status": "ok",
     "timestamp": 1619103283459,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "P3alrjFxoTKw",
    "outputId": "51b47fba-fc0d-4c33-c849-96a8fa74ed33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |                                           #  | 1633641 Elapsed Time: 0:03:17\n",
      "\n",
      "Saving top 1302499 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 17705685 words in total\n",
      "  It has 1302499 unique words\n",
      "  Your top-1302499 words are 100.0000 percent of all words\n",
      "  Your most common word \"மற்றும்\" occurred 169299 times\n",
      "  The least common word in your top-k is \"20107\" with 1 times\n",
      "  The first word with 2 occurrences is \"ஸ்ரீகுமாரின்\" at place 527554\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x557adfe78000 @  0x7f213914a1e7 0x557adeaa0772 0x557adea34358 0x557adea13290 0x557ade9ff096 0x7f21372e3bf7 0x557adea00ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x557b7f310000 @  0x7f213914a1e7 0x557adeaa0772 0x557adea8a7aa 0x557adea8b1c8 0x557adea132ad 0x557ade9ff096 0x7f21372e3bf7 0x557adea00ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 17705685 types 1302502\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:15630024 2:4031271168 3:7558633472\n",
      "tcmalloc: large alloc 7558635520 bytes == 0x557adfd6a000 @  0x7f213914a1e7 0x557adeaa0772 0x557adea8a7aa 0x557adea8b1c8 0x557adea1384e 0x557ade9ff096 0x7f21372e3bf7 0x557adea00ada\n",
      "tcmalloc: large alloc 4031275008 bytes == 0x557d92aec000 @  0x7f213914a1e7 0x557adeaa0772 0x557adea8a7aa 0x557adea8b1c8 0x557adea13c3d 0x557ade9ff096 0x7f21372e3bf7 0x557adea00ada\n",
      "Statistics:\n",
      "1 1302502 D1=0.705154 D2=1.0249 D3+=1.42037\n",
      "2 9207901 D1=0.846809 D2=1.19535 D3+=1.36953\n",
      "3 984973/13627966 D1=0.908611 D2=1.36447 D3+=1.46371\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 259 assuming -p 1.5\n",
      "probing 317 assuming -r models -p 1.5\n",
      "trie    150 without quantization\n",
      "trie     95 assuming -q 8 -b 8 quantization \n",
      "trie    132 assuming -a 22 array pointer compression\n",
      "trie     77 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:15630024 2:147326416 3:19699460\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "*******#############################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:15630024 2:147326416 3:19699460\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15533084 kB\tVmRSS:3252944 kB\tRSSMax:3298524 kB\tuser:28.6449\tsys:6.24005\tCPU:34.8858\treal:45.4871\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamil/Wiki_CommonVoiceTrain.txt' --output_dir . \\\n",
    "  --top_k 1302499 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377448,
     "status": "ok",
     "timestamp": 1619103389962,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "JRjrUfa1oT8Y",
    "outputId": "52d8f05c-3a69-4c61-e0bd-0f64257c4fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "1302499 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-1302499.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585456,
     "status": "ok",
     "timestamp": 1619103975442,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "uFbMPlzwoT_Y",
    "outputId": "3f4fb61f-d5fb-4627-bb7b-154eaf34f390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-22 14:56:37.363342: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-22 14:56:37.363947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55924900f480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 14:56:37.363991: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 14:56:37.445283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 14:56:37.535085: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 14:56:37.535245: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d3bb02250d04): /proc/driver/nvidia/version does not exist\n",
      "I0422 14:56:39.371003 140164407691136 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4290\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:09:28                                  \n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.374066, CER: 0.170045, loss: 28.758249\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 67.215157\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19183354.wav\n",
      " - src: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      " - res: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 63.920784\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21342637.wav\n",
      " - src: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      " - res: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.018182, loss: 59.189087\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19528754.wav\n",
      " - src: \"குற்றாலக் குறவஞ்சியை இயற்றியவர் திரிகூட ராசப்ப கவிராயர்\"\n",
      " - res: \"குற்றாலக் குறவஞ்சியை இயற்றியவர் திரிகூட ராசப்ப கவிராயர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 58.988403\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19777692.wav\n",
      " - src: \"விளைந்துள்ள எவற்றினுக்கும் பெயர்களெலாங் கண்டு\"\n",
      " - res: \"விளைந்துள்ள எவற்றினுக்கும் பெயர்களெலாங் கண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 56.896183\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19140222.wav\n",
      " - src: \"கொந்தளிப்பில் நல்லதொரு கொள்கை முளைப்பதெங்கே \"\n",
      " - res: \"கொந்தளிப்பில் நல்லதொரு கொள்கை முளைப்பதெங்கே \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.083333, loss: 34.112633\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20585644.wav\n",
      " - src: \"தோளின் துரிதத்தைக் கண்டாயோ என்நண்பா \"\n",
      " - res: \"தண்டின் துரிதத்தைக் கண்டாயோ என்நண்பா \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.075000, loss: 34.101753\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21387186.wav\n",
      " - src: \"இம்மட்டும் இன்று கதையை நிறுத்துகின்றேன் \"\n",
      " - res: \"மட்டும் இன்று கதையை நிறுத்துகின்றேன் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.103448, loss: 33.383495\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20378038.wav\n",
      " - src: \"கூடத்திலே மனப் பாடத்திலே விழி\"\n",
      " - res: \"கூடத்திலே மனப் பாடத்திலே வள\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.170732, loss: 33.015728\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20848725.wav\n",
      " - src: \"கையை விரித்தெங்கள் மெய்யினைப் போர்த்தோம் \"\n",
      " - res: \"கையை விரித்தெங்கள் மீனை போர்த்தோம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.105263, loss: 32.666801\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20371819.wav\n",
      " - src: \"அம்மலையை ஓர்நொடியில் தூக்கிவந் தையாவே \"\n",
      " - res: \"அம்மலையை கொடியில் தூக்கிவந் தையாவே \"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.333333, CER: 0.250000, loss: 5.861474\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21294334.wav\n",
      " - src: \"ஓடப்பர் உயரப்பர் எல்லாம்மாறி\"\n",
      " - res: \"ஓப்பன் உயரப் எல்லாம் மாறி \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.500000, loss: 29.282240\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20591146.wav\n",
      " - src: \"ஆம்புலன்ஸ கூப்பிடு\"\n",
      " - res: \"ஆம்பர் சதகுப்பி டு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.400000, loss: 21.578150\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19970071.wav\n",
      " - src: \"எண்ணி எண்ணிஅயர்வாள் \"\n",
      " - res: \"என்ன என்ன அருவாள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.411765, loss: 20.057592\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21302913.wav\n",
      " - src: \"இலையேஉண விலையேகதி\"\n",
      " - res: \"நிறைய உணவினையே தி\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.155556, loss: 26.557959\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395015.wav\n",
      " - src: \"உளம்துடித்தார் எனினும்அவர் உயிர்வாழ்கின்றார் \"\n",
      " - res: \"உலர் குடித்தால் எனினும் அவர் உயிர் வாழ்கின்றார் \"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --test_output_file '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/WikiVocab/Output/wikiarticles.json' \\\n",
    "  --checkpoint_dir '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\\n",
    "  \"$@\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0FP573uhvQKJyGzEDiZ3/",
   "collapsed_sections": [],
   "name": "WikiVocab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
