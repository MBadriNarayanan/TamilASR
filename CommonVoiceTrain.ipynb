{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19678,
     "status": "ok",
     "timestamp": 1623345341050,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "AHIT9mvlgF_N",
    "outputId": "f6bcbf93-0eb9-4d11-d97e-b1923db90ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 391163,
     "status": "ok",
     "timestamp": 1623345732209,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "7MguIThogLJ7",
    "outputId": "c585a6a1-f155-4029-a9bd-846733b35920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "/content/drive/My Drive/deepspeech\n",
      "Collecting pip==20.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 14.9MB/s \n",
      "\u001b[?25hCollecting wheel==0.34.2\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting setuptools==46.1.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
      "\u001b[K     |████████████████████████████████| 583kB 50.9MB/s \n",
      "\u001b[31mERROR: tensorflow 2.5.0 has requirement wheel~=0.35, but you'll have wheel 0.34.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip, wheel, setuptools\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "  Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Found existing installation: setuptools 57.0.0\n",
      "    Uninstalling setuptools-57.0.0:\n",
      "      Successfully uninstalled setuptools-57.0.0\n",
      "Successfully installed pip-20.0.2 setuptools-46.1.3 wheel-0.34.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/drive/My%20Drive/deepspeech\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 279 kB/s \n",
      "\u001b[?25hCollecting progressbar2\n",
      "  Downloading progressbar2-3.53.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting six\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyxdg\n",
      "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 8.1 MB/s \n",
      "\u001b[?25hCollecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 76.1 MB/s \n",
      "\u001b[?25hCollecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opuslib==2.0.0\n",
      "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-2.8.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 45.4 MB/s \n",
      "\u001b[?25hCollecting sox\n",
      "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 49.3 MB/s \n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 8.5 MB/s \n",
      "\u001b[?25hCollecting numba==0.47.0\n",
      "  Downloading numba-0.47.0-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 51.2 MB/s \n",
      "\u001b[?25hCollecting llvmlite==0.31.0\n",
      "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "\u001b[K     |████████████████████████████████| 203 kB 70.4 MB/s \n",
      "\u001b[?25hCollecting soundfile\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting ds_ctcdecoder==0.7.4\n",
      "  Downloading ds_ctcdecoder-0.7.4-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 47.5 MB/s \n",
      "\u001b[?25hCollecting tensorflow==1.15.2\n",
      "  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 110.5 MB 1.1 MB/s \n",
      "\u001b[?25hCollecting python-utils>=2.3.0\n",
      "  Downloading python_utils-2.5.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.8.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 11.6 MB/s \n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 7.5 MB/s \n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 80.4 MB/s \n",
      "\u001b[?25hCollecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.17-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 58.0 MB/s \n",
      "\u001b[?25hCollecting scipy!=1.4.0\n",
      "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4 MB 153 kB/s \n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.2 MB/s \n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 77.7 MB/s \n",
      "\u001b[?25hCollecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 60.1 MB/s \n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 78.3 MB/s \n",
      "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 78.6 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 80.6 MB/s \n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 80.9 MB/s \n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 8.0 MB/s \n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading setuptools-57.0.0-py3-none-any.whl (821 kB)\n",
      "\u001b[K     |████████████████████████████████| 821 kB 55.8 MB/s \n",
      "\u001b[?25hCollecting decorator>=3.0.0\n",
      "  Downloading decorator-5.0.9-py3-none-any.whl (8.9 kB)\n",
      "Collecting scikit-learn!=0.19.0,>=0.14.0\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.4.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 621 kB/s \n",
      "\u001b[?25hCollecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "\u001b[K     |████████████████████████████████| 323 kB 80.8 MB/s \n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 70.4 MB/s \n",
      "\u001b[?25hCollecting joblib>=0.14\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 66.2 MB/s \n",
      "\u001b[?25hCollecting cffi>=1.0\n",
      "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "\u001b[K     |████████████████████████████████| 402 kB 74.6 MB/s \n",
      "\u001b[?25hCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.5 MB/s \n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 52.4 MB/s \n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 35.6 MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 75.7 MB/s \n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 7.5 MB/s \n",
      "\u001b[?25hCollecting wheel>=0.26; python_version >= \"3\"\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 9.1 MB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.38.0-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 42.8 MB/s \n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.0.1-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 73.4 MB/s \n",
      "\u001b[?25hCollecting pyparsing>=2.1.0\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting PyYAML>=3.12\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 67.0 MB/s \n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 82.1 MB/s \n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 6.1 MB/s \n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.5.0-py3-none-any.whl (17 kB)\n",
      "Collecting greenlet!=0.4.17; python_version >= \"3\"\n",
      "  Downloading greenlet-1.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 76.9 MB/s \n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 78.0 MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 68.2 MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 9.3 MB/s \n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 61.7 MB/s \n",
      "\u001b[?25hCollecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting typing-extensions; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Collecting attrs>=16.3.0\n",
      "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 3.0 MB/s \n",
      "\u001b[?25hCollecting wcwidth>=0.1.7\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-2.0.1-cp37-cp37m-manylinux2010_x86_64.whl (31 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: opuslib, bs4, resampy, audioread, wrapt, termcolor, gast, pyperclip\n",
      "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=ec0261169c01db4de52f841412d3203ba902c75ab57adb9145d168425b3c206e\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/ba/d4/0e81231a9797fbb262ae3a54fd761fab850db7f32d94a3283a\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=8dcd51bd14bdb2036d8f62a12ffa9c6933809b21e1c6e7402e60f92ce5144305\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320720 sha256=689ef0bb9bf04db7403bf865f44d0d47d95882b726f9b84084882be2a824c228\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/18/0a/8ad18a597d8333a142c9789338a96a6208f1198d290ece356c\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23142 sha256=364adfb90d3cb517492a502e181231fa59aed0c78e1b259cf14f8db441e466e8\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/7b/eb/213741ccc0678f63e346ab8dff10495995ca3f426af87b8d88\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68669 sha256=fbc421b5b18709edd6feb1d5a4b499d75586281b7f045c519f0fb2d678d60186\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=db1d479b2a799984d7e38563737944a6eda44dcc4a4d3ddad8ad8f7613259d02\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=54d2d6693f937af53e4bd1d228bd41458000e648be2879b38e26f8f016f1a592\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=2ea08000a6e2bed79fc8b81cbaa822eecf62c94f79a3f9f47a9eb9eca6685f54\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built opuslib bs4 resampy audioread wrapt termcolor gast pyperclip\n",
      "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: networkx 2.5.1 has requirement decorator<5,>=4.3, but you'll have decorator 5.0.9 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: moviepy 0.2.3.5 has requirement decorator<5.0,>=4.0.2, but you'll have decorator 5.0.9 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: flask 1.1.4 has requirement Werkzeug<2.0,>=0.15, but you'll have werkzeug 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, six, python-utils, progressbar2, pyxdg, attrdict, absl-py, semver, opuslib, colorlog, zipp, typing-extensions, importlib-metadata, pbr, stevedore, colorama, pyperclip, attrs, wcwidth, cmd2, pyparsing, PrettyTable, PyYAML, cliff, cmaes, packaging, MarkupSafe, Mako, python-dateutil, greenlet, sqlalchemy, python-editor, alembic, scipy, tqdm, optuna, sox, soupsieve, beautifulsoup4, bs4, pytz, pandas, chardet, urllib3, certifi, idna, requests, llvmlite, setuptools, numba, decorator, threadpoolctl, joblib, scikit-learn, appdirs, pooch, pycparser, cffi, soundfile, resampy, audioread, librosa, ds-ctcdecoder, wrapt, opt-einsum, astor, termcolor, gast, protobuf, grpcio, werkzeug, markdown, wheel, tensorboard, tensorflow-estimator, google-pasta, cached-property, h5py, keras-applications, keras-preprocessing, tensorflow, deepspeech-training\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: python-utils\n",
      "    Found existing installation: python-utils 2.5.6\n",
      "    Uninstalling python-utils-2.5.6:\n",
      "      Successfully uninstalled python-utils-2.5.6\n",
      "  Attempting uninstall: progressbar2\n",
      "    Found existing installation: progressbar2 3.38.0\n",
      "    Uninstalling progressbar2-3.38.0:\n",
      "      Successfully uninstalled progressbar2-3.38.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: semver\n",
      "    Found existing installation: semver 2.13.0\n",
      "    Uninstalling semver-2.13.0:\n",
      "      Successfully uninstalled semver-2.13.0\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.2.0\n",
      "    Uninstalling attrs-21.2.0:\n",
      "      Successfully uninstalled attrs-21.2.0\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: PrettyTable\n",
      "    Found existing installation: prettytable 2.1.0\n",
      "    Uninstalling prettytable-2.1.0:\n",
      "      Successfully uninstalled prettytable-2.1.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 1.1.0\n",
      "    Uninstalling greenlet-1.1.0:\n",
      "      Successfully uninstalled greenlet-1.1.0\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.15\n",
      "    Uninstalling SQLAlchemy-1.4.15:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.15\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "  Attempting uninstall: bs4\n",
      "    Found existing installation: bs4 0.0.1\n",
      "    Uninstalling bs4-0.0.1:\n",
      "      Successfully uninstalled bs4-0.0.1\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.12.5\n",
      "    Uninstalling certifi-2020.12.5:\n",
      "      Successfully uninstalled certifi-2020.12.5\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.34.0\n",
      "    Uninstalling llvmlite-0.34.0:\n",
      "      Successfully uninstalled llvmlite-0.34.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 46.1.3\n",
      "    Uninstalling setuptools-46.1.3:\n",
      "      Successfully uninstalled setuptools-46.1.3\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.51.2\n",
      "    Uninstalling numba-0.51.2:\n",
      "      Successfully uninstalled numba-0.51.2\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "  Attempting uninstall: appdirs\n",
      "    Found existing installation: appdirs 1.4.4\n",
      "    Uninstalling appdirs-1.4.4:\n",
      "      Successfully uninstalled appdirs-1.4.4\n",
      "  Attempting uninstall: pooch\n",
      "    Found existing installation: pooch 1.3.0\n",
      "    Uninstalling pooch-1.3.0:\n",
      "      Successfully uninstalled pooch-1.3.0\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.5\n",
      "    Uninstalling cffi-1.14.5:\n",
      "      Successfully uninstalled cffi-1.14.5\n",
      "  Attempting uninstall: soundfile\n",
      "    Found existing installation: SoundFile 0.10.3.post1\n",
      "    Uninstalling SoundFile-0.10.3.post1:\n",
      "      Successfully uninstalled SoundFile-0.10.3.post1\n",
      "  Attempting uninstall: resampy\n",
      "    Found existing installation: resampy 0.2.2\n",
      "    Uninstalling resampy-0.2.2:\n",
      "      Successfully uninstalled resampy-0.2.2\n",
      "  Attempting uninstall: audioread\n",
      "    Found existing installation: audioread 2.1.9\n",
      "    Uninstalling audioread-2.1.9:\n",
      "      Successfully uninstalled audioread-2.1.9\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.8.0\n",
      "    Uninstalling librosa-0.8.0:\n",
      "      Successfully uninstalled librosa-0.8.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: astor\n",
      "    Found existing installation: astor 0.8.1\n",
      "    Uninstalling astor-0.8.1:\n",
      "      Successfully uninstalled astor-0.8.1\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.4\n",
      "    Uninstalling protobuf-3.12.4:\n",
      "      Successfully uninstalled protobuf-3.12.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.3.4\n",
      "    Uninstalling Markdown-3.3.4:\n",
      "      Successfully uninstalled Markdown-3.3.4\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: cached-property\n",
      "    Found existing installation: cached-property 1.5.2\n",
      "    Uninstalling cached-property-1.5.2:\n",
      "      Successfully uninstalled cached-property-1.5.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "  Running setup.py develop for deepspeech-training\n",
      "Successfully installed Mako-1.1.4 MarkupSafe-2.0.1 PrettyTable-2.1.0 PyYAML-5.4.1 absl-py-0.12.0 alembic-1.6.5 appdirs-1.4.4 astor-0.8.1 attrdict-2.0.1 attrs-21.2.0 audioread-2.1.9 beautifulsoup4-4.9.3 bs4-0.0.1 cached-property-1.5.2 certifi-2021.5.30 cffi-1.14.5 chardet-4.0.0 cliff-3.8.0 cmaes-0.8.2 cmd2-2.0.1 colorama-0.4.4 colorlog-5.0.1 decorator-5.0.9 deepspeech-training ds-ctcdecoder-0.7.4 gast-0.2.2 google-pasta-0.2.0 greenlet-1.1.0 grpcio-1.38.0 h5py-3.2.1 idna-2.10 importlib-metadata-4.5.0 joblib-1.0.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 librosa-0.8.1 llvmlite-0.31.0 markdown-3.3.4 numba-0.47.0 numpy-1.20.3 opt-einsum-3.3.0 optuna-2.8.0 opuslib-2.0.0 packaging-20.9 pandas-1.2.4 pbr-5.6.0 pooch-1.4.0 progressbar2-3.53.1 protobuf-3.17.3 pycparser-2.20 pyparsing-2.4.7 pyperclip-1.8.2 python-dateutil-2.8.1 python-editor-1.0.4 python-utils-2.5.6 pytz-2021.1 pyxdg-0.27 requests-2.25.1 resampy-0.2.2 scikit-learn-0.24.2 scipy-1.6.3 semver-2.13.0 setuptools-57.0.0 six-1.16.0 soundfile-0.10.3.post1 soupsieve-2.2.1 sox-1.4.1 sqlalchemy-1.4.17 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0 threadpoolctl-2.1.0 tqdm-4.61.0 typing-extensions-3.10.0.0 urllib3-1.26.5 wcwidth-0.2.5 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "astor",
         "cffi",
         "dateutil",
         "decorator",
         "google",
         "numpy",
         "pandas",
         "pkg_resources",
         "pyparsing",
         "pytz",
         "six",
         "wcwidth"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: /content/drive/My Drive/deepspeech/tc/native_client.tar.xz\n",
      "libdeepspeech.so\n",
      "LICENSE\n",
      "deepspeech\n",
      "deepspeech.h\n",
      "README.mozilla\n",
      "Found existing installation: protobuf 3.17.3\n",
      "Uninstalling protobuf-3.17.3:\n",
      "  Successfully uninstalled protobuf-3.17.3\n",
      "Collecting protobuf==3.8\n",
      "  Downloading protobuf-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 13.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (57.0.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (1.16.0)\n",
      "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-api-core 1.26.3 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-3.8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 1.15.2\n",
      "Uninstalling tensorflow-1.15.2:\n",
      "  Successfully uninstalled tensorflow-1.15.2\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "TensorFlow 1.x selected.\n",
      "Collecting tensorflow-gpu==1.15.2\n",
      "  Downloading tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.9 MB 35 kB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.16.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.20.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.8.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.38.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.36.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2) (57.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.4)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (1.5.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.1)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.15.2\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/deepspeech\n",
    "%cd /content/drive/My\\ Drive/deepspeech\n",
    "\n",
    "!pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3\n",
    "!pip3 install --upgrade --force-reinstall -e .\n",
    "!python util/taskcluster.py --arch gpu --target tc/ --branch v0.7.4\n",
    "\n",
    "!pip uninstall -y protobuf\n",
    "!pip install protobuf==3.8\n",
    "\n",
    "# Uninstall existing tf and install the correct\n",
    "!pip uninstall -y tensorflow\n",
    "!pip uninstall -y tensorflow-gpu\n",
    "%tensorflow_version 1.x\n",
    "!pip install tensorflow-gpu==1.15.2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1623345732210,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "1AYgdzdpgOGX",
    "outputId": "a235b5be-4e98-4393-ded4-e88e311c5cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1623345733021,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "xWzED5M8gPzU"
   },
   "outputs": [],
   "source": [
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/lmplz'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/build_binary'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/filter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK-H36qDywS8"
   },
   "source": [
    "### Entire Common Voice Vocab Scorer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6204,
     "status": "ok",
     "timestamp": 1623345739220,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "8DIDCERDgRgx",
    "outputId": "d160e18d-b6dd-4b32-af83-4fe40c0668ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |     #                                          | 12162 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 20000 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 47155 words in total\n",
      "  It has 14479 unique words\n",
      "  Your top-20000 words are 100.0000 percent of all words\n",
      "  Your most common word \"என்று\" occurred 228 times\n",
      "  The least common word in your top-k is \"தொழிந்தா\" with 1 times\n",
      "  The first word with 2 occurrences is \"பாக்கியும்\" at place 13550\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2666733568 bytes == 0x562cd12e0000 @  0x7fb452e931e7 0x562ccfd12772 0x562ccfca6358 0x562ccfc85290 0x562ccfc71096 0x7fb45102cbf7 0x562ccfc72ada\n",
      "tcmalloc: large alloc 8889098240 bytes == 0x562d70212000 @  0x7fb452e931e7 0x562ccfd12772 0x562ccfcfc7aa 0x562ccfcfd1c8 0x562ccfc852ad 0x562ccfc71096 0x7fb45102cbf7 0x562ccfc72ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 47155 types 14482\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:173784 2:4028110848 3:7552708096\n",
      "tcmalloc: large alloc 7552712704 bytes == 0x562cd11d2000 @  0x7fb452e931e7 0x562ccfd12772 0x562ccfcfc7aa 0x562ccfcfd1c8 0x562ccfc8584e 0x562ccfc71096 0x7fb45102cbf7 0x562ccfc72ada\n",
      "tcmalloc: large alloc 4028112896 bytes == 0x562f827ec000 @  0x7fb452e931e7 0x562ccfd12772 0x562ccfcfc7aa 0x562ccfcfd1c8 0x562ccfc85c3d 0x562ccfc71096 0x7fb45102cbf7 0x562ccfc72ada\n",
      "Statistics:\n",
      "1 14482 D1=0.831029 D2=1.28316 D3+=1.48486\n",
      "2 23047 D1=0.776126 D2=0.587603 D3+=2.74954\n",
      "3 18714/20155 D1=0.0611812 D2=1.87627 D3+=2.99747\n",
      "Memory estimate for binary LM:\n",
      "type      kB\n",
      "probing 1236 assuming -p 1.5\n",
      "probing 1428 assuming -r models -p 1.5\n",
      "trie     701 without quantization\n",
      "trie     519 assuming -q 8 -b 8 quantization \n",
      "trie     677 assuming -a 22 array pointer compression\n",
      "trie     495 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:173784 2:368752 3:374280\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "#######################################################################################*****########\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:173784 2:368752 3:374280\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15506020 kB\tVmRSS:2629876 kB\tRSSMax:2647848 kB\tuser:0.21648\tsys:1.11247\tCPU:1.32899\treal:1.46151\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/deepspeech/data/lm\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/vocab.txt' --output_dir . \\\n",
    "  --top_k 20000 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3211,
     "status": "ok",
     "timestamp": 1623345742427,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "wj784nwlgRw7",
    "outputId": "3425c7cb-3fd8-4fc0-d7db-171c8b653d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "14479 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/deepspeech/data/lm\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-20000.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8893287,
     "status": "ok",
     "timestamp": 1599229010815,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "J5vsHhFlgRzn",
    "outputId": "b90fe517-5687-4353-dc10-c557b7456186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2020-09-04 11:48:45.379589: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2020-09-04 11:48:45.379882: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24f2bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-04 11:48:45.379920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-09-04 11:48:45.389418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-09-04 11:48:45.593518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:45.594368: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24f2d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-09-04 11:48:45.594401: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2020-09-04 11:48:45.595536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:45.596114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-09-04 11:48:45.596508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-04 11:48:45.873736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-04 11:48:46.030415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-09-04 11:48:46.058054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-09-04 11:48:46.316625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-09-04 11:48:46.338852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-09-04 11:48:46.857308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-04 11:48:46.857511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:46.858166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:46.858777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-09-04 11:48:46.862968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-04 11:48:46.868027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-04 11:48:46.868062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-09-04 11:48:46.868074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-09-04 11:48:46.869482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:46.870138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:46.870775: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2020-09-04 11:48:46.870846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "I0904 11:48:48.114967 140041166776192 utils.py:141] NumExpr defaulting to 2 threads.\n",
      "2020-09-04 11:48:49.891793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:49.892595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-09-04 11:48:49.892682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-04 11:48:49.892716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-04 11:48:49.892736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-09-04 11:48:49.892755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-09-04 11:48:49.892776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-09-04 11:48:49.892796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-09-04 11:48:49.892842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-04 11:48:49.892930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:49.893576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:49.894139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "W0904 11:48:50.448092 140041166776192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "W0904 11:48:50.448449 140041166776192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "W0904 11:48:50.448649 140041166776192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0904 11:48:50.603115 140041166776192 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "W0904 11:48:50.605455 140041166776192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:245: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0904 11:48:50.683688 140041166776192 deprecation.py:323] From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:245: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2020-09-04 11:48:51.324181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:51.324776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-09-04 11:48:51.324858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-04 11:48:51.324885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-04 11:48:51.324902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-09-04 11:48:51.324919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-09-04 11:48:51.324937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-09-04 11:48:51.324955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-09-04 11:48:51.324973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-04 11:48:51.325054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:51.325713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:51.326284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-09-04 11:48:51.326334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-04 11:48:51.326355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-09-04 11:48:51.326379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-09-04 11:48:51.326475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:51.327078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 11:48:51.327633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "D Session opened.\n",
      "I Could not find best validating checkpoint.\n",
      "I Could not find most recent checkpoint.\n",
      "I Initializing all variables.\n",
      "I STARTING Optimization\n",
      "I Training epoch 0...\n",
      "2020-09-04 11:48:59.834569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-04 11:49:26.461519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "I Finished training epoch 0 - loss: 121.468656\n",
      "I Validating epoch 0 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 0 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 112.296571\n",
      "I Saved new best validating model with loss 112.296571 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-143\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 1...\n",
      "I Finished training epoch 1 - loss: 106.886000\n",
      "I Validating epoch 1 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 1 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 107.621562\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "W0904 12:43:30.066945 140041166776192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "I Saved new best validating model with loss 107.621562 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-286\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 2...\n",
      "I Finished training epoch 2 - loss: 100.653698\n",
      "I Validating epoch 2 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 2 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 93.487107\n",
      "I Saved new best validating model with loss 93.487107 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-429\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 3...\n",
      "I Finished training epoch 3 - loss: 88.053606\n",
      "I Validating epoch 3 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 3 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 80.818123\n",
      "I Saved new best validating model with loss 80.818123 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-572\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 4...\n",
      "I Finished training epoch 4 - loss: 77.220666\n",
      "I Validating epoch 4 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 4 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 68.687035\n",
      "I Saved new best validating model with loss 68.687035 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-715\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 5...\n",
      "I Finished training epoch 5 - loss: 67.632719\n",
      "I Validating epoch 5 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 5 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 60.002236\n",
      "I Saved new best validating model with loss 60.002236 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-858\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 6...\n",
      "I Finished training epoch 6 - loss: 59.686821\n",
      "I Validating epoch 6 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 6 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 53.336809\n",
      "I Saved new best validating model with loss 53.336809 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-1001\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 7...\n",
      "I Finished training epoch 7 - loss: 53.919626\n",
      "I Validating epoch 7 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 7 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 48.616904\n",
      "I Saved new best validating model with loss 48.616904 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-1144\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 8...\n",
      "I Finished training epoch 8 - loss: 49.870952\n",
      "I Validating epoch 8 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 8 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 45.464928\n",
      "I Saved new best validating model with loss 45.464928 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-1287\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 9...\n",
      "I Finished training epoch 9 - loss: 46.740057\n",
      "I Validating epoch 9 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 9 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 43.142570\n",
      "I Saved new best validating model with loss 43.142570 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-1430\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 10...\n",
      "I Finished training epoch 10 - loss: 44.155984\n",
      "I Validating epoch 10 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 10 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 41.205202\n",
      "I Saved new best validating model with loss 41.205202 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-1573\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 11...\n",
      "I Finished training epoch 11 - loss: 41.934653\n",
      "I Validating epoch 11 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 11 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 39.473718\n",
      "I Saved new best validating model with loss 39.473718 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-1716\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 12...\n",
      "I Finished training epoch 12 - loss: 39.999261\n",
      "I Validating epoch 12 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 12 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 38.347600\n",
      "I Saved new best validating model with loss 38.347600 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-1859\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 13...\n",
      "I Finished training epoch 13 - loss: 38.437956\n",
      "I Validating epoch 13 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 13 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 36.662745\n",
      "I Saved new best validating model with loss 36.662745 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-2002\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 14...\n",
      "I Finished training epoch 14 - loss: 36.827860\n",
      "I Validating epoch 14 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 14 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 35.483428\n",
      "I Saved new best validating model with loss 35.483428 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-2145\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 15...\n",
      "I Finished training epoch 15 - loss: 35.507679\n",
      "I Validating epoch 15 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 15 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 34.474439\n",
      "I Saved new best validating model with loss 34.474439 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-2288\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 16...\n",
      "I Finished training epoch 16 - loss: 34.289565\n",
      "I Validating epoch 16 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 16 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 33.886972\n",
      "I Saved new best validating model with loss 33.886972 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-2431\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 17...\n",
      "I Finished training epoch 17 - loss: 33.138568\n",
      "I Validating epoch 17 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 17 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 32.981246\n",
      "I Saved new best validating model with loss 32.981246 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-2574\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 18...\n",
      "I Finished training epoch 18 - loss: 32.209051\n",
      "I Validating epoch 18 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 18 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 32.425328\n",
      "I Saved new best validating model with loss 32.425328 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-2717\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 19...\n",
      "I Finished training epoch 19 - loss: 31.092502\n",
      "I Validating epoch 19 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 19 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 32.124041\n",
      "I Saved new best validating model with loss 32.124041 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-2860\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 20...\n",
      "I Finished training epoch 20 - loss: 30.221486\n",
      "I Validating epoch 20 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 20 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 31.670616\n",
      "I Saved new best validating model with loss 31.670616 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-3003\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 21...\n",
      "I Finished training epoch 21 - loss: 29.345471\n",
      "I Validating epoch 21 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 21 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 31.380116\n",
      "I Saved new best validating model with loss 31.380116 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-3146\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 22...\n",
      "I Finished training epoch 22 - loss: 28.551262\n",
      "I Validating epoch 22 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 22 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 31.011821\n",
      "I Saved new best validating model with loss 31.011821 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-3289\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 23...\n",
      "I Finished training epoch 23 - loss: 27.583576\n",
      "I Validating epoch 23 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 23 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.426837\n",
      "I Saved new best validating model with loss 30.426837 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-3432\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 24...\n",
      "I Finished training epoch 24 - loss: 26.802561\n",
      "I Validating epoch 24 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 24 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.130173\n",
      "I Saved new best validating model with loss 30.130173 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-3575\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 25...\n",
      "I Finished training epoch 25 - loss: 26.108460\n",
      "I Validating epoch 25 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 25 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.044433\n",
      "I Saved new best validating model with loss 30.044433 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-3718\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 26...\n",
      "I Finished training epoch 26 - loss: 25.308518\n",
      "I Validating epoch 26 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 26 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.902282\n",
      "I Saved new best validating model with loss 29.902282 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-3861\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 27...\n",
      "I Finished training epoch 27 - loss: 24.579265\n",
      "I Validating epoch 27 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 27 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.571609\n",
      "I Saved new best validating model with loss 29.571609 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4004\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 28...\n",
      "I Finished training epoch 28 - loss: 24.022645\n",
      "I Validating epoch 28 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 28 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.412504\n",
      "I Saved new best validating model with loss 29.412504 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4147\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 29...\n",
      "I Finished training epoch 29 - loss: 23.302047\n",
      "I Validating epoch 29 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 29 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.123295\n",
      "I Saved new best validating model with loss 29.123295 to: /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4290\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 30...\n",
      "I Finished training epoch 30 - loss: 22.563133\n",
      "I Validating epoch 30 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 30 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.257149\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 31...\n",
      "I Finished training epoch 31 - loss: 22.087821\n",
      "I Validating epoch 31 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 31 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.347341\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 32...\n",
      "I Finished training epoch 32 - loss: 21.576288\n",
      "I Validating epoch 32 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 32 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.244947\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 33...\n",
      "I Finished training epoch 33 - loss: 20.912195\n",
      "I Validating epoch 33 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 33 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.517734\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 34...\n",
      "I Finished training epoch 34 - loss: 20.402283\n",
      "I Validating epoch 34 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 34 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.460231\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 35...\n",
      "I Finished training epoch 35 - loss: 19.871763\n",
      "I Validating epoch 35 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 35 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.702542\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 36...\n",
      "I Finished training epoch 36 - loss: 19.301658\n",
      "I Validating epoch 36 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 36 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.987367\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 37...\n",
      "I Finished training epoch 37 - loss: 18.802350\n",
      "I Validating epoch 37 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 37 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.761420\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 38...\n",
      "I Finished training epoch 38 - loss: 18.361726\n",
      "I Validating epoch 38 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 38 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.045160\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 39...\n",
      "I Finished training epoch 39 - loss: 17.933978\n",
      "I Validating epoch 39 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 39 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.325413\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 40...\n",
      "I Finished training epoch 40 - loss: 17.363654\n",
      "I Validating epoch 40 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 40 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.817466\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 41...\n",
      "I Finished training epoch 41 - loss: 16.873741\n",
      "I Validating epoch 41 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 41 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.652443\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 42...\n",
      "I Finished training epoch 42 - loss: 16.406810\n",
      "I Validating epoch 42 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 42 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.778100\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 43...\n",
      "I Finished training epoch 43 - loss: 15.902630\n",
      "I Validating epoch 43 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 43 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.012260\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 44...\n",
      "I Finished training epoch 44 - loss: 15.522092\n",
      "I Validating epoch 44 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 44 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 29.791281\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 45...\n",
      "I Finished training epoch 45 - loss: 15.090355\n",
      "I Validating epoch 45 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 45 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.250533\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 46...\n",
      "I Finished training epoch 46 - loss: 14.634793\n",
      "I Validating epoch 46 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 46 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.220051\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 47...\n",
      "I Finished training epoch 47 - loss: 14.279809\n",
      "I Validating epoch 47 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 47 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 30.984099\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 48...\n",
      "I Finished training epoch 48 - loss: 13.847174\n",
      "I Validating epoch 48 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 48 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 31.124970\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 49...\n",
      "I Finished training epoch 49 - loss: 13.550759\n",
      "I Validating epoch 49 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 49 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 31.561258\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 50...\n",
      "I Finished training epoch 50 - loss: 13.177944\n",
      "I Validating epoch 50 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 50 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 32.196024\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 51...\n",
      "I Finished training epoch 51 - loss: 12.944562\n",
      "I Validating epoch 51 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 51 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 32.318527\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 52...\n",
      "I Finished training epoch 52 - loss: 12.482703\n",
      "I Validating epoch 52 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 52 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 33.193174\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 53...\n",
      "I Finished training epoch 53 - loss: 12.170187\n",
      "I Validating epoch 53 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 53 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 32.344864\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 54...\n",
      "I Finished training epoch 54 - loss: 11.785297\n",
      "I Validating epoch 54 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 54 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 33.619308\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 55...\n",
      "I Finished training epoch 55 - loss: 11.430142\n",
      "I Validating epoch 55 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 55 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 33.513715\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 56...\n",
      "I Finished training epoch 56 - loss: 11.241827\n",
      "I Validating epoch 56 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 56 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 33.683028\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 57...\n",
      "I Finished training epoch 57 - loss: 10.940867\n",
      "I Validating epoch 57 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 57 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 33.896291\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 58...\n",
      "I Finished training epoch 58 - loss: 10.545782\n",
      "I Validating epoch 58 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 58 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 34.195039\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 59...\n",
      "I Finished training epoch 59 - loss: 10.317895\n",
      "I Validating epoch 59 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 59 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 34.531982\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 60...\n",
      "I Finished training epoch 60 - loss: 10.032928\n",
      "I Validating epoch 60 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 60 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 34.265937\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 61...\n",
      "I Finished training epoch 61 - loss: 9.610579\n",
      "I Validating epoch 61 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 61 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 34.764932\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 62...\n",
      "I Finished training epoch 62 - loss: 9.390791\n",
      "I Validating epoch 62 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 62 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 35.409316\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 63...\n",
      "I Finished training epoch 63 - loss: 9.097913\n",
      "I Validating epoch 63 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 63 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 35.951681\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 64...\n",
      "I Finished training epoch 64 - loss: 8.886354\n",
      "I Validating epoch 64 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 64 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 35.905756\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 65...\n",
      "I Finished training epoch 65 - loss: 8.664154\n",
      "I Validating epoch 65 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 65 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 35.939329\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 66...\n",
      "I Finished training epoch 66 - loss: 8.467084\n",
      "I Validating epoch 66 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 66 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 35.942321\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 67...\n",
      "I Finished training epoch 67 - loss: 8.415899\n",
      "I Validating epoch 67 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 67 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 35.867992\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 68...\n",
      "I Finished training epoch 68 - loss: 8.037790\n",
      "I Validating epoch 68 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 68 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 36.748147\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 69...\n",
      "I Finished training epoch 69 - loss: 7.711781\n",
      "I Validating epoch 69 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 69 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 37.357213\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 70...\n",
      "I Finished training epoch 70 - loss: 7.487732\n",
      "I Validating epoch 70 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 70 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 37.805293\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 71...\n",
      "I Finished training epoch 71 - loss: 7.288599\n",
      "I Validating epoch 71 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 71 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 37.017273\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 72...\n",
      "I Finished training epoch 72 - loss: 7.084060\n",
      "I Validating epoch 72 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 72 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 38.331175\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 73...\n",
      "I Finished training epoch 73 - loss: 6.882641\n",
      "I Validating epoch 73 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 73 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 38.433666\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 74...\n",
      "I Finished training epoch 74 - loss: 6.695924\n",
      "I Validating epoch 74 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 74 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 39.615685\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 75...\n",
      "I Finished training epoch 75 - loss: 6.406559\n",
      "I Validating epoch 75 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 75 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 39.679209\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 76...\n",
      "I Finished training epoch 76 - loss: 6.279515\n",
      "I Validating epoch 76 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 76 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 39.980454\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 77...\n",
      "I Finished training epoch 77 - loss: 5.981994\n",
      "I Validating epoch 77 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 77 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 41.315710\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 78...\n",
      "I Finished training epoch 78 - loss: 5.864039\n",
      "I Validating epoch 78 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 78 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 40.557069\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 79...\n",
      "I Finished training epoch 79 - loss: 5.630716\n",
      "I Validating epoch 79 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 79 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 40.710936\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 80...\n",
      "I Finished training epoch 80 - loss: 5.545815\n",
      "I Validating epoch 80 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 80 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 41.645951\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 81...\n",
      "I Finished training epoch 81 - loss: 5.347227\n",
      "I Validating epoch 81 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 81 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 42.074605\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 82...\n",
      "I Finished training epoch 82 - loss: 5.266397\n",
      "I Validating epoch 82 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 82 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 42.398218\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 83...\n",
      "I Finished training epoch 83 - loss: 5.122382\n",
      "I Validating epoch 83 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 83 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 43.271860\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 84...\n",
      "I Finished training epoch 84 - loss: 4.912231\n",
      "I Validating epoch 84 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 84 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 44.439542\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 85...\n",
      "I Finished training epoch 85 - loss: 4.911983\n",
      "I Validating epoch 85 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 85 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 45.023450\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 86...\n",
      "I Finished training epoch 86 - loss: 4.696085\n",
      "I Validating epoch 86 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 86 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 44.788591\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 87...\n",
      "I Finished training epoch 87 - loss: 4.610975\n",
      "I Validating epoch 87 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 87 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 45.244915\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 88...\n",
      "I Finished training epoch 88 - loss: 4.468523\n",
      "I Validating epoch 88 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 88 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 45.959675\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 89...\n",
      "I Finished training epoch 89 - loss: 4.316401\n",
      "I Validating epoch 89 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 89 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 46.069349\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 90...\n",
      "I Finished training epoch 90 - loss: 4.313762\n",
      "I Validating epoch 90 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 90 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 45.684704\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 91...\n",
      "I Finished training epoch 91 - loss: 4.077528\n",
      "I Validating epoch 91 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 91 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 46.809816\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 92...\n",
      "I Finished training epoch 92 - loss: 4.098759\n",
      "I Validating epoch 92 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 92 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 45.860616\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 93...\n",
      "I Finished training epoch 93 - loss: 3.904368\n",
      "I Validating epoch 93 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 93 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 46.201640\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 94...\n",
      "I Finished training epoch 94 - loss: 3.872559\n",
      "I Validating epoch 94 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 94 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 45.575518\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 95...\n",
      "I Finished training epoch 95 - loss: 3.856329\n",
      "I Validating epoch 95 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 95 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 47.437336\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 96...\n",
      "I Finished training epoch 96 - loss: 3.721881\n",
      "I Validating epoch 96 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 96 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 47.190561\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 97...\n",
      "I Finished training epoch 97 - loss: 3.638614\n",
      "I Validating epoch 97 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 97 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 47.023525\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 98...\n",
      "I Finished training epoch 98 - loss: 3.480421\n",
      "I Validating epoch 98 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 98 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 47.163541\n",
      "--------------------------------------------------------------------------------\n",
      "I Training epoch 99...\n",
      "I Finished training epoch 99 - loss: 3.409008\n",
      "I Validating epoch 99 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv...\n",
      "I Finished validating epoch 99 on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv - loss: 48.755948\n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 2:17:37.289385\n",
      "D Session closed.\n",
      "2020-09-04 14:06:36.813463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:06:36.814033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-09-04 14:06:36.826511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-04 14:06:36.826579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-04 14:06:36.826604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-09-04 14:06:36.826624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-09-04 14:06:36.826646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-09-04 14:06:36.826665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-09-04 14:06:36.826685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-04 14:06:36.826772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:06:36.827247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:06:36.827719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-09-04 14:06:36.827931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-04 14:06:36.827950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-09-04 14:06:36.827961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-09-04 14:06:36.828066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:06:36.828569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:06:36.828988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "I Loading best validating checkpoint from /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4290\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "WARNING:tensorflow:From /content/drive/My Drive/deepspeech/training/deepspeech_training/util/checkpoints.py:70: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "W0904 14:06:36.852046 140041166776192 deprecation.py:323] From /content/drive/My Drive/deepspeech/training/deepspeech_training/util/checkpoints.py:70: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "I Test epoch...\n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.135755, CER: 0.082652, loss: 28.758253\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 89.670227\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21282837.wav\n",
      " - src: \"காலத்தி னால்செய்த நன்றி சிறிதுஎனினும் ஞாலத்தின் மானப் பெரிது \"\n",
      " - res: \"காலத்தி னால்செய்த நன்றி சிறிதுஎனினும் ஞாலத்தின் மானப் பெரிது \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.020408, loss: 77.357826\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19785719.wav\n",
      " - src: \"பிறர் மனதை புண்படுத்தகூடிய வார்த்தைகளை தவிருங்கள்\"\n",
      " - res: \"பிறர் மனதை புண்படுத்தகூடிய வார்த்தைகளை தவிருங்கள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 73.912697\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19523139.wav\n",
      " - src: \"கற்க கசடறக் கற்பவை கற்றபின் நிற்க அதற்குத் தக \"\n",
      " - res: \"கற்க கசடறக் கற்பவை கற்றபின் நிற்க அதற்குத் தக \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 73.304070\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21302859.wav\n",
      " - src: \"நன்றி மறப்பது நன்றன்று நன்றல்லது அன்றே மறப்பது நன்று \"\n",
      " - res: \"நன்றி மறப்பது நன்றன்று நன்றல்லது அன்றே மறப்பது நன்று \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 67.433960\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20593143.wav\n",
      " - src: \"செல்வத்துள் செல்வம் செவிச்செல்வம் அச்செல்வம் செல்வத்துளெல்லாந் தலை \"\n",
      " - res: \"செல்வத்துள் செல்வம் செவிச்செல்வம் அச்செல்வம் செல்வத்துளெல்லாந் தலை \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 15.388196\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21293979.wav\n",
      " - src: \"ஓர்நொடியிற் சஞ்சீவி பர்வதத்தை ஓடிப்போய் \"\n",
      " - res: \"ஓர்நொடியிற் சஞ்சீவி பர்வதத்தை ஓடிப்போய் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 15.385484\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20513688.wav\n",
      " - src: \"தமிழுக்கு மதுவென்று பேர் இன்பத்\"\n",
      " - res: \"தமிழுக்கு மதுவென்று பேர் இன்பத்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 15.359595\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19917645.wav\n",
      " - src: \"தையல் சொல் கேளேல் \"\n",
      " - res: \"தையல் சொல் கேளேல் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 15.345208\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21291624.wav\n",
      " - src: \"ஆயிற்று மைத்துனர் அப்புறம் சென்றார் \"\n",
      " - res: \"ஆயிற்று மைத்துனர் அப்புறம் சென்றார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 15.300763\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19970494.wav\n",
      " - src: \"பேச்செடுத்தாள் வஞ்சி பிறகும் ஒருசத்தம் \"\n",
      " - res: \"பேச்செடுத்தாள் வஞ்சி பிறகும் ஒருசத்தம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 3.735262\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_22102752.wav\n",
      " - src: \"ஆறு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.250000, CER: 0.674419, loss: 87.520638\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21310586.wav\n",
      " - src: \"இந்தியாவின் தேசத்தந்தை மகாத்மா காந்தியடிகள்\"\n",
      " - res: \"இங்கி ரின்றிச் தன்றி மர்மத்தைக் தான் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.250000, CER: 0.459459, loss: 59.327892\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19172012.wav\n",
      " - src: \"உள்ளம் எதிர்பார்த்த ஓவியமே என்மடியில்\"\n",
      " - res: \"உளம் தெருப் பார்த்த வழியே என்னதென் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.250000, CER: 0.307692, loss: 57.630249\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21289759.wav\n",
      " - src: \"மன்றல்செயும் விஷயத்தில் ஒன்றில் மட்டும்\"\n",
      " - res: \"மன்ன செய் வசத்தில் ஒன்றி மற்றும்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.416667, loss: 30.154242\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_22435893.wav\n",
      " - src: \"ஃபயர்ஃபாக்ஸ்\"\n",
      " - res: \"தாயர் பாக்கி\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "WARNING:tensorflow:From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:687: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "W0904 14:16:48.217430 140041166776192 module_wrapper.py:139] From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:687: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:786: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0904 14:16:48.682879 140041166776192 module_wrapper.py:139] From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:786: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-09-04 14:16:48.689719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:16:48.690206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-09-04 14:16:48.690307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-04 14:16:48.690334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-04 14:16:48.690358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-09-04 14:16:48.690376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-09-04 14:16:48.690395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-09-04 14:16:48.690416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-09-04 14:16:48.690437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-04 14:16:48.690514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:16:48.691024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:16:48.691479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-09-04 14:16:48.691551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-04 14:16:48.691568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-09-04 14:16:48.691579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-09-04 14:16:48.691687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:16:48.692188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-04 14:16:48.692643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "I Loading best validating checkpoint from /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4290\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "WARNING:tensorflow:From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:804: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0904 14:16:48.840100 140041166776192 deprecation.py:323] From /content/drive/My Drive/deepspeech/training/deepspeech_training/train.py:804: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0904 14:16:48.840348 140041166776192 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 12 variables.\n",
      "I0904 14:16:48.860559 140041166776192 graph_util_impl.py:334] Froze 12 variables.\n",
      "INFO:tensorflow:Converted 12 variables to const ops.\n",
      "I0904 14:16:48.916582 140041166776192 graph_util_impl.py:394] Converted 12 variables to const ops.\n",
      "I Models exported at /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Export\n",
      "I Model metadata file saved to /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Export/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python -u DeepSpeech.py --noshow_progressbar \\\n",
    "  --train_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Train.csv' \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --dev_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv' \\\n",
    "  --feature_cache '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/feature_cache' \\\n",
    "  --learning_rate 0.0001 \\\n",
    "  --train_batch_size 64 \\\n",
    "  --dev_batch_size 64 \\\n",
    "  --test_batch_size 64 \\\n",
    "  --checkpoint_dir '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints' \\\n",
    "  --export_dir '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Export' \\\n",
    "  --summary_dir '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Summary' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --dropout_rate 0.4 \\\n",
    "  --epochs 100 \\\n",
    "  --test_output_file '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Output/output.json' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --log_level 0 \\\n",
    "  --max_to_keep 10 \\\n",
    "  --noearly_stop \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2DdAHQPx5-C"
   },
   "source": [
    "### Common Voice Train Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4049,
     "status": "ok",
     "timestamp": 1623345748010,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "kOJNo4dTxoLK",
    "outputId": "caf71414-a410-40fe-d2cb-ecd30531b523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |    #                                            | 9162 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 13857 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 35598 words in total\n",
      "  It has 13857 unique words\n",
      "  Your top-13857 words are 100.0000 percent of all words\n",
      "  Your most common word \"என்று\" occurred 166 times\n",
      "  The least common word in your top-k is \"நெஞ்சத்திலே\" with 1 times\n",
      "  The first word with 2 occurrences is \"இழந்தேன்\" at place 9835\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2666733568 bytes == 0x5559f1046000 @  0x7ff3daeb81e7 0x5559eec95772 0x5559eec29358 0x5559eec08290 0x5559eebf4096 0x7ff3d9051bf7 0x5559eebf5ada\n",
      "tcmalloc: large alloc 8889098240 bytes == 0x555a8ff78000 @  0x7ff3daeb81e7 0x5559eec95772 0x5559eec7f7aa 0x5559eec801c8 0x5559eec082ad 0x5559eebf4096 0x7ff3d9051bf7 0x5559eebf5ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 35598 types 13860\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:166320 2:4028113408 3:7552712704\n",
      "tcmalloc: large alloc 7552712704 bytes == 0x5559f0f38000 @  0x7ff3daeb81e7 0x5559eec95772 0x5559eec7f7aa 0x5559eec801c8 0x5559eec0884e 0x5559eebf4096 0x7ff3d9051bf7 0x5559eebf5ada\n",
      "tcmalloc: large alloc 4028121088 bytes == 0x555ca2552000 @  0x7ff3daeb81e7 0x5559eec95772 0x5559eec7f7aa 0x5559eec801c8 0x5559eec08c3d 0x5559eebf4096 0x7ff3d9051bf7 0x5559eebf5ada\n",
      "Statistics:\n",
      "1 13860 D1=0.834797 D2=1.25252 D3+=1.53494\n",
      "2 21960 D1=0.80139 D2=1.15444 D3+=2.40195\n",
      "3 12695/19169 D1=0.258155 D2=1.72683 D3+=2.98615\n",
      "Memory estimate for binary LM:\n",
      "type      kB\n",
      "probing 1089 assuming -p 1.5\n",
      "probing 1272 assuming -r models -p 1.5\n",
      "trie     638 without quantization\n",
      "trie     479 assuming -q 8 -b 8 quantization \n",
      "trie     617 assuming -a 22 array pointer compression\n",
      "trie     458 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:166320 2:351360 3:253900\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "###############################################*******************##################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:166320 2:351360 3:253900\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15506028 kB\tVmRSS:2629972 kB\tRSSMax:2648600 kB\tuser:0.200795\tsys:1.11487\tCPU:1.3157\treal:1.41976\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/deepspeech/data/lm\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamil/CommonVoiceTrain.txt' --output_dir . \\\n",
    "  --top_k 13857 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 977,
     "status": "ok",
     "timestamp": 1623345748985,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "h0j2CLfJxobJ",
    "outputId": "4ad223c0-491d-43a1-8b2b-8d9ca8501f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "13857 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/deepspeech/data/lm\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-13857.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615701,
     "status": "ok",
     "timestamp": 1619102001828,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "z94DTrd7hhxa",
    "outputId": "aa49b605-9654-43f5-e3cf-c95ec3bfcd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-22 14:23:22.387989: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-22 14:23:22.388428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557bcbead480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 14:23:22.388492: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 14:23:22.465243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 14:23:22.523774: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 14:23:22.523835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (4053d43e1bf4): /proc/driver/nvidia/version does not exist\n",
      "I0422 14:23:24.021935 139867705792384 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints/best_dev-4290\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:09:50                                  \n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.247002, CER: 0.115962, loss: 28.758249\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.020408, loss: 77.357826\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19785719.wav\n",
      " - src: \"பிறர் மனதை புண்படுத்தகூடிய வார்த்தைகளை தவிருங்கள்\"\n",
      " - res: \"பிறர் மனதை புண்படுத்தகூடிய வார்த்தைகளை தவிருங்கள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 73.912682\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19523139.wav\n",
      " - src: \"கற்க கசடறக் கற்பவை கற்றபின் நிற்க அதற்குத் தக \"\n",
      " - res: \"கற்க கசடறக் கற்பவை கற்றபின் நிற்க அதற்குத் தக \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 73.304085\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21302859.wav\n",
      " - src: \"நன்றி மறப்பது நன்றன்று நன்றல்லது அன்றே மறப்பது நன்று \"\n",
      " - res: \"நன்றி மறப்பது நன்றன்று நன்றல்லது அன்றே மறப்பது நன்று \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 67.433983\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20593143.wav\n",
      " - src: \"செல்வத்துள் செல்வம் செவிச்செல்வம் அச்செல்வம் செல்வத்துளெல்லாந் தலை \"\n",
      " - res: \"செல்வத்துள் செல்வம் செவிச்செல்வம் அச்செல்வம் செல்வத்துளெல்லாந் தலை \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 67.215157\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19183354.wav\n",
      " - src: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      " - res: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 11.611705\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20575156.wav\n",
      " - src: \"தாய்மேற் பிள்ளை சாய்ந்து கிடந்தது \"\n",
      " - res: \"தாய்மேற் பிள்ளை சாய்ந்து கிடந்தது \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 11.590739\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21350730.wav\n",
      " - src: \"கதறுகின்ற மனிதர்காள் \"\n",
      " - res: \"கதறுகின்ற மனிதர்காள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 11.573637\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19093886.wav\n",
      " - src: \"சரிபோ என்று தலைவி சொன்னாள் \"\n",
      " - res: \"சரிபோ என்று தலைவி சொன்னாள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.024390, loss: 11.545793\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21288718.wav\n",
      " - src: \"நான்நினைத்த வண்ணம் நடந்ததுதான் ஆச்சரியம் \"\n",
      " - res: \"நான்நினைத்த வண்ணம் நடந்ததுதான் ஆச்சரியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.037037, loss: 11.517365\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19083499.wav\n",
      " - src: \"சாய்ந்த பாலை நக்கித் தன்தலை\"\n",
      " - res: \"சாய்ந்த பாலை நக்கித் தன்தலை \"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.170213, loss: 34.351604\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21386923.wav\n",
      " - src: \"எதிர்இருந்தோர் இதுகேட்டார் மிகஇரக்கங் கொண்டார் \"\n",
      " - res: \"எதிர் ருந்தோர் இது கேட்டார் மிக லிருக்கும் கொண்டார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.210526, loss: 17.088900\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21380737.wav\n",
      " - src: \"கைம்பெண்ணாய் வருந்தாதே பழிஎன்றன் மீதே \"\n",
      " - res: \"கைம்பெண் நாய் இருந்ததே பழி என்றன் நீள \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.400000, loss: 14.939498\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21277402.wav\n",
      " - src: \"தொல்லை தரும்புவியில்\"\n",
      " - res: \"கொள்ளை தரும் பொறியல் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.416667, loss: 30.154232\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_22435893.wav\n",
      " - src: \"ஃபயர்ஃபாக்ஸ்\"\n",
      " - res: \"தாயர் பாக்கி\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.155556, loss: 26.557959\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395015.wav\n",
      " - src: \"உளம்துடித்தார் எனினும்அவர் உயிர்வாழ்கின்றார் \"\n",
      " - res: \"பலர் குடித்தார் எனினும் அவர் உயிர் வாழ்கின்றார் \"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --test_output_file '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Output/CommonVoiceTrainScorerOutput.json' \\\n",
    "  --checkpoint_dir '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/CommonVoiceVocab/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOHjOOOc9/ydaHy7BcctDl1",
   "collapsed_sections": [],
   "name": "CommonVoiceDataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
