{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369428,
     "status": "ok",
     "timestamp": 1619423559811,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "w6mfodhh4eW4",
    "outputId": "34c27660-b20f-4be0-8a15-13f29040662c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 793385,
     "status": "ok",
     "timestamp": 1619423983798,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "wSbhNzIN4i1P",
    "outputId": "9951d65b-f25d-4df5-87fb-6c1057ef81ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "/content/drive/My Drive/deepspeech\n",
      "Collecting pip==20.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 9.1MB/s \n",
      "\u001b[?25hCollecting wheel==0.34.2\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
      "Collecting setuptools==46.1.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl (582kB)\n",
      "\u001b[K     |████████████████████████████████| 583kB 17.3MB/s \n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement wheel~=0.35, but you'll have wheel 0.34.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip, wheel, setuptools\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "  Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Found existing installation: setuptools 56.0.0\n",
      "    Uninstalling setuptools-56.0.0:\n",
      "      Successfully uninstalled setuptools-56.0.0\n",
      "Successfully installed pip-20.0.2 setuptools-46.1.3 wheel-0.34.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/drive/My%20Drive/deepspeech\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 176 kB/s \n",
      "\u001b[?25hCollecting progressbar2\n",
      "  Downloading progressbar2-3.53.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pyxdg\n",
      "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 73.0 MB/s \n",
      "\u001b[?25hCollecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opuslib==2.0.0\n",
      "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-2.7.0-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 62.7 MB/s \n",
      "\u001b[?25hCollecting sox\n",
      "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 63.4 MB/s \n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 9.7 MB/s \n",
      "\u001b[?25hCollecting numba==0.47.0\n",
      "  Downloading numba-0.47.0-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 69.0 MB/s \n",
      "\u001b[?25hCollecting llvmlite==0.31.0\n",
      "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 76.5 MB/s \n",
      "\u001b[?25hCollecting soundfile\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting ds_ctcdecoder==0.7.4\n",
      "  Downloading ds_ctcdecoder-0.7.4-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 57.7 MB/s \n",
      "\u001b[?25hCollecting tensorflow==1.15.2\n",
      "  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 110.5 MB 40 kB/s \n",
      "\u001b[?25hCollecting python-utils>=2.3.0\n",
      "  Downloading python_utils-2.5.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.11-cp37-cp37m-manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 63.2 MB/s \n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 4.9 MB/s \n",
      "\u001b[?25hCollecting packaging>=20.0\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 6.7 MB/s \n",
      "\u001b[?25hCollecting scipy!=1.4.0\n",
      "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4 MB 64 kB/s \n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.5.8-py2.py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 80.4 MB/s \n",
      "\u001b[?25hCollecting cliff\n",
      "  Downloading cliff-3.7.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 10.6 MB/s \n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 71.7 MB/s \n",
      "\u001b[?25hCollecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 68.3 MB/s \n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 67.7 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 56.2 MB/s \n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 7.3 MB/s \n",
      "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 78.7 MB/s \n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 76.8 MB/s \n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading setuptools-56.0.0-py3-none-any.whl (784 kB)\n",
      "\u001b[K     |████████████████████████████████| 784 kB 49.7 MB/s \n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 73.5 MB/s \n",
      "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0\n",
      "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 98 kB/s \n",
      "\u001b[?25hCollecting joblib>=0.14\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 64.1 MB/s \n",
      "\u001b[?25hCollecting decorator>=3.0.0\n",
      "  Downloading decorator-5.0.7-py3-none-any.whl (8.8 kB)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "\u001b[K     |████████████████████████████████| 323 kB 75.4 MB/s \n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 582 kB/s \n",
      "\u001b[?25hCollecting cffi>=1.0\n",
      "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "\u001b[K     |████████████████████████████████| 402 kB 73.0 MB/s \n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting wheel>=0.26; python_version >= \"3\"\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 59.4 MB/s \n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 62.1 MB/s \n",
      "\u001b[?25hCollecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 67.7 MB/s \n",
      "\u001b[?25hCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 361 kB/s \n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.3 MB/s \n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.7 MB/s \n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.37.0-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 46.5 MB/s \n",
      "\u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting greenlet!=0.4.17; python_version >= \"3\"\n",
      "  Downloading greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 75.7 MB/s \n",
      "\u001b[?25hCollecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.8 MB/s \n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 61.4 MB/s \n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-1.5.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 75.5 MB/s \n",
      "\u001b[?25hCollecting PyYAML>=3.12\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 68.6 MB/s \n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 8.1 MB/s \n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 78.5 MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 79.9 MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 9.2 MB/s \n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 62.9 MB/s \n",
      "\u001b[?25hCollecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting wcwidth>=0.1.7\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Collecting attrs>=16.3.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 7.7 MB/s \n",
      "\u001b[?25hCollecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: opuslib, bs4, librosa, audioread, resampy, termcolor, gast, wrapt, pyperclip\n",
      "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=ade8ba2f87f2379fb224ae465632fdcfbf1510106c431abe3a3dc472174d3245\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/ba/d4/0e81231a9797fbb262ae3a54fd761fab850db7f32d94a3283a\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=06560fa72a801d15ab5a2b95d96a2a8c457cbd45e49567df46669f4d409a4198\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201374 sha256=0a76314d813ebb116ce5065f17589a3036604dbf71ab6bd2319a1860b4a4bd10\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23142 sha256=ffa15c70d28808bf3209c4e23cc400addf7ca427940c548c2dda5e2293968373\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/7b/eb/213741ccc0678f63e346ab8dff10495995ca3f426af87b8d88\n",
      "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320720 sha256=4212719f1f5057f366c6faa936a25ed628b91be51d19038c8733b19fe9571a71\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/18/0a/8ad18a597d8333a142c9789338a96a6208f1198d290ece356c\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=35789f7b46a0a9ee210c7c311c7f2758ddb88cd1eb801a46745e0c4bd496407f\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=6aa68b6c2535bdb28528b9c99d3146852f5f9dbe5f173aab562825583caf52ae\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68673 sha256=4d435105cb6ede8154f2ea3586f5720dad38f009f12278e71451df43418252dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=3d47b57b3b6b1949bb71965f88335e7d817e165658a3c4e7d1ca25235475f9a3\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built opuslib bs4 librosa audioread resampy termcolor gast wrapt pyperclip\n",
      "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: networkx 2.5.1 has requirement decorator<5,>=4.3, but you'll have decorator 5.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: moviepy 0.2.3.5 has requirement decorator<5.0,>=4.0.2, but you'll have decorator 5.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, six, python-utils, progressbar2, pyxdg, attrdict, absl-py, semver, opuslib, cmaes, typing-extensions, zipp, importlib-metadata, greenlet, sqlalchemy, tqdm, pyparsing, packaging, scipy, python-editor, python-dateutil, MarkupSafe, Mako, alembic, pbr, wcwidth, pyperclip, attrs, colorama, cmd2, PyYAML, stevedore, PrettyTable, cliff, colorlog, optuna, sox, soupsieve, beautifulsoup4, bs4, pytz, pandas, urllib3, idna, chardet, certifi, requests, setuptools, llvmlite, numba, audioread, threadpoolctl, joblib, scikit-learn, decorator, resampy, pycparser, cffi, soundfile, appdirs, pooch, librosa, ds-ctcdecoder, astor, wheel, termcolor, protobuf, werkzeug, markdown, grpcio, tensorboard, gast, tensorflow-estimator, wrapt, cached-property, h5py, keras-applications, google-pasta, keras-preprocessing, opt-einsum, tensorflow, deepspeech-training\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: python-utils\n",
      "    Found existing installation: python-utils 2.5.6\n",
      "    Uninstalling python-utils-2.5.6:\n",
      "      Successfully uninstalled python-utils-2.5.6\n",
      "  Attempting uninstall: progressbar2\n",
      "    Found existing installation: progressbar2 3.38.0\n",
      "    Uninstalling progressbar2-3.38.0:\n",
      "      Successfully uninstalled progressbar2-3.38.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.1\n",
      "    Uninstalling importlib-metadata-3.10.1:\n",
      "      Successfully uninstalled importlib-metadata-3.10.1\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 1.0.0\n",
      "    Uninstalling greenlet-1.0.0:\n",
      "      Successfully uninstalled greenlet-1.0.0\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.7\n",
      "    Uninstalling SQLAlchemy-1.4.7:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.7\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.3.0\n",
      "    Uninstalling attrs-20.3.0:\n",
      "      Successfully uninstalled attrs-20.3.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: PrettyTable\n",
      "    Found existing installation: prettytable 2.1.0\n",
      "    Uninstalling prettytable-2.1.0:\n",
      "      Successfully uninstalled prettytable-2.1.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "  Attempting uninstall: bs4\n",
      "    Found existing installation: bs4 0.0.1\n",
      "    Uninstalling bs4-0.0.1:\n",
      "      Successfully uninstalled bs4-0.0.1\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.12.5\n",
      "    Uninstalling certifi-2020.12.5:\n",
      "      Successfully uninstalled certifi-2020.12.5\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 46.1.3\n",
      "    Uninstalling setuptools-46.1.3:\n",
      "      Successfully uninstalled setuptools-46.1.3\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.34.0\n",
      "    Uninstalling llvmlite-0.34.0:\n",
      "      Successfully uninstalled llvmlite-0.34.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.51.2\n",
      "    Uninstalling numba-0.51.2:\n",
      "      Successfully uninstalled numba-0.51.2\n",
      "  Attempting uninstall: audioread\n",
      "    Found existing installation: audioread 2.1.9\n",
      "    Uninstalling audioread-2.1.9:\n",
      "      Successfully uninstalled audioread-2.1.9\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Attempting uninstall: resampy\n",
      "    Found existing installation: resampy 0.2.2\n",
      "    Uninstalling resampy-0.2.2:\n",
      "      Successfully uninstalled resampy-0.2.2\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.5\n",
      "    Uninstalling cffi-1.14.5:\n",
      "      Successfully uninstalled cffi-1.14.5\n",
      "  Attempting uninstall: soundfile\n",
      "    Found existing installation: SoundFile 0.10.3.post1\n",
      "    Uninstalling SoundFile-0.10.3.post1:\n",
      "      Successfully uninstalled SoundFile-0.10.3.post1\n",
      "  Attempting uninstall: appdirs\n",
      "    Found existing installation: appdirs 1.4.4\n",
      "    Uninstalling appdirs-1.4.4:\n",
      "      Successfully uninstalled appdirs-1.4.4\n",
      "  Attempting uninstall: pooch\n",
      "    Found existing installation: pooch 1.3.0\n",
      "    Uninstalling pooch-1.3.0:\n",
      "      Successfully uninstalled pooch-1.3.0\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.8.0\n",
      "    Uninstalling librosa-0.8.0:\n",
      "      Successfully uninstalled librosa-0.8.0\n",
      "  Attempting uninstall: astor\n",
      "    Found existing installation: astor 0.8.1\n",
      "    Uninstalling astor-0.8.1:\n",
      "      Successfully uninstalled astor-0.8.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.12.4\n",
      "    Uninstalling protobuf-3.12.4:\n",
      "      Successfully uninstalled protobuf-3.12.4\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.3.4\n",
      "    Uninstalling Markdown-3.3.4:\n",
      "      Successfully uninstalled Markdown-3.3.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "  Running setup.py develop for deepspeech-training\n",
      "Successfully installed Mako-1.1.4 MarkupSafe-1.1.1 PrettyTable-2.1.0 PyYAML-5.4.1 absl-py-0.12.0 alembic-1.5.8 appdirs-1.4.4 astor-0.8.1 attrdict-2.0.1 attrs-20.3.0 audioread-2.1.9 beautifulsoup4-4.9.3 bs4-0.0.1 cached-property-1.5.2 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 decorator-5.0.7 deepspeech-training ds-ctcdecoder-0.7.4 gast-0.2.2 google-pasta-0.2.0 greenlet-1.0.0 grpcio-1.37.0 h5py-3.2.1 idna-2.10 importlib-metadata-4.0.1 joblib-1.0.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 librosa-0.8.0 llvmlite-0.31.0 markdown-3.3.4 numba-0.47.0 numpy-1.20.2 opt-einsum-3.3.0 optuna-2.7.0 opuslib-2.0.0 packaging-20.9 pandas-1.2.4 pbr-5.5.1 pooch-1.3.0 progressbar2-3.53.1 protobuf-3.15.8 pycparser-2.20 pyparsing-2.4.7 pyperclip-1.8.2 python-dateutil-2.8.1 python-editor-1.0.4 python-utils-2.5.6 pytz-2021.1 pyxdg-0.27 requests-2.25.1 resampy-0.2.2 scikit-learn-0.24.1 scipy-1.6.3 semver-2.13.0 setuptools-56.0.0 six-1.15.0 soundfile-0.10.3.post1 soupsieve-2.2.1 sox-1.4.1 sqlalchemy-1.4.11 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0 threadpoolctl-2.1.0 tqdm-4.60.0 typing-extensions-3.7.4.3 urllib3-1.26.4 wcwidth-0.2.5 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "astor",
         "cffi",
         "dateutil",
         "decorator",
         "google",
         "numpy",
         "pandas",
         "pkg_resources",
         "pyparsing",
         "pytz",
         "six",
         "wcwidth"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: /content/drive/My Drive/deepspeech/tc/native_client.tar.xz\n",
      "libdeepspeech.so\n",
      "LICENSE\n",
      "deepspeech\n",
      "deepspeech.h\n",
      "README.mozilla\n",
      "Found existing installation: protobuf 3.15.8\n",
      "Uninstalling protobuf-3.15.8:\n",
      "  Successfully uninstalled protobuf-3.15.8\n",
      "Collecting protobuf==3.8\n",
      "  Downloading protobuf-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 7.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (56.0.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.8) (1.15.0)\n",
      "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-api-core 1.26.3 has requirement protobuf>=3.12.0, but you'll have protobuf 3.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-3.8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 1.15.2\n",
      "Uninstalling tensorflow-1.15.2:\n",
      "  Successfully uninstalled tensorflow-1.15.2\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "TensorFlow 1.x selected.\n",
      "Collecting tensorflow-gpu==1.15.2\n",
      "  Downloading tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.9 MB 34 kB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.20.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.36.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.37.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (56.0.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.0.1)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (1.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.7.4.3)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.15.2\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/deepspeech\n",
    "%cd /content/drive/My\\ Drive/deepspeech\n",
    "\n",
    "!pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3\n",
    "!pip3 install --upgrade --force-reinstall -e .\n",
    "!python util/taskcluster.py --arch gpu --target tc/ --branch v0.7.4\n",
    "\n",
    "!pip uninstall -y protobuf\n",
    "!pip install protobuf==3.8\n",
    "\n",
    "# Uninstall existing tf and install the correct\n",
    "!pip uninstall -y tensorflow\n",
    "!pip uninstall -y tensorflow-gpu\n",
    "%tensorflow_version 1.x\n",
    "!pip install tensorflow-gpu==1.15.2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 793364,
     "status": "ok",
     "timestamp": 1619423983802,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "9CGCMxT64k-6",
    "outputId": "5b212a92-0114-4f83-c652-776f68c3ce71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 793888,
     "status": "ok",
     "timestamp": 1619423984333,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "AfVffGOO4mUw"
   },
   "outputs": [],
   "source": [
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/lmplz'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/build_binary'\n",
    "\n",
    "!chmod a+x '/content/drive/My Drive/kenlm/build/bin/filter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKqnStE6ccH9"
   },
   "source": [
    "## Testing on Wiki Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296794,
     "status": "ok",
     "timestamp": 1619096346252,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "rrdjcSI99KZL",
    "outputId": "935d9333-e029-4e90-fddc-42d4bce46303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |                                             #| 1637918 Elapsed Time: 0:03:27\n",
      "\n",
      "Saving top 1303210 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 17734992 words in total\n",
      "  It has 1303210 unique words\n",
      "  Your top-1303210 words are 100.0000 percent of all words\n",
      "  Your most common word \"மற்றும்\" occurred 169339 times\n",
      "  The least common word in your top-k is \"20107\" with 1 times\n",
      "  The first word with 2 occurrences is \"ஸ்ரீகுமாரின்\" at place 528162\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x55978aa12000 @  0x7fa7fc4ac1e7 0x559788a62772 0x5597889f6358 0x5597889d5290 0x5597889c1096 0x7fa7fa645bf7 0x5597889c2ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x559829eaa000 @  0x7fa7fc4ac1e7 0x559788a62772 0x559788a4c7aa 0x559788a4d1c8 0x5597889d52ad 0x5597889c1096 0x7fa7fa645bf7 0x5597889c2ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 17734992 types 1303213\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:15638556 2:4031269376 3:7558630400\n",
      "tcmalloc: large alloc 7558635520 bytes == 0x55978a904000 @  0x7fa7fc4ac1e7 0x559788a62772 0x559788a4c7aa 0x559788a4d1c8 0x5597889d584e 0x5597889c1096 0x7fa7fa645bf7 0x5597889c2ada\n",
      "tcmalloc: large alloc 4031275008 bytes == 0x559a3d686000 @  0x7fa7fc4ac1e7 0x559788a62772 0x559788a4c7aa 0x559788a4d1c8 0x5597889d5c3d 0x5597889c1096 0x7fa7fa645bf7 0x5597889c2ada\n",
      "Statistics:\n",
      "1 1303213 D1=0.705136 D2=1.0251 D3+=1.42077\n",
      "2 9216617 D1=0.846745 D2=1.19547 D3+=1.36983\n",
      "3 993561/13642328 D1=0.907997 D2=1.35843 D3+=1.47874\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 260 assuming -p 1.5\n",
      "probing 318 assuming -r models -p 1.5\n",
      "trie    150 without quantization\n",
      "trie     95 assuming -q 8 -b 8 quantization \n",
      "trie    132 assuming -a 22 array pointer compression\n",
      "trie     78 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:15638556 2:147465872 3:19871220\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "*******#############################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:15638556 2:147465872 3:19871220\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15533080 kB\tVmRSS:3253612 kB\tRSSMax:3299340 kB\tuser:30.4214\tsys:10.1997\tCPU:40.6211\treal:51.4402\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Wiki_CommonVoiceTrain_OpenSLR.txt' --output_dir . \\\n",
    "  --top_k 1303210 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163345,
     "status": "ok",
     "timestamp": 1619096452797,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "QuXZimaV9leR",
    "outputId": "98ce4343-ead1-41e7-895d-5ce0d7c27092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "1303210 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-1303210.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358955,
     "status": "ok",
     "timestamp": 1619096832018,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "eX7UUPXNKbp1",
    "outputId": "07fd7770-641d-4354-a816-8a4f46edb6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-22 13:01:17.542707: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-22 13:01:17.544808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c90da71480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 13:01:17.544883: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 13:01:17.553406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 13:01:17.649286: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 13:01:17.649349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dfb948aa4d81): /proc/driver/nvidia/version does not exist\n",
      "I0422 13:01:18.576826 139800554198912 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:05:48                                  \n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.369894, CER: 0.164239, loss: 28.240021\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.075157\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19183354.wav\n",
      " - src: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      " - res: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.044212\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21342637.wav\n",
      " - src: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      " - res: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 58.942009\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20565411.wav\n",
      " - src: \"ஒறுத்தார்க்கு ஒருநாளை இன்பம் பொறுத்தார்க்குப் பொன்றுந் துணையும் புகழ் \"\n",
      " - res: \"ஒறுத்தார்க்கு ஒருநாளை இன்பம் பொறுத்தார்க்குப் பொன்றுந் துணையும் புகழ் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 51.598667\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19533182.wav\n",
      " - src: \"எனைத்தானும் நல்லவை கேட்க அனைத்தானும் ஆன்ற பெருமை தரும் \"\n",
      " - res: \"எனைத்தானும் நல்லவை கேட்க அனைத்தானும் ஆன்ற பெருமை தரும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 50.231178\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20329519.wav\n",
      " - src: \"தாழ்வகற்ற எண்ணுங்கால் சாக்குருவி வேதாந்தம் \"\n",
      " - res: \"தாழ்வகற்ற எண்ணுங்கால் சாக்குருவி வேதாந்தம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.176471, loss: 34.323708\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21277645.wav\n",
      " - src: \"இடிக்குரற் சிங்கநேர் இறையே எனினும்\"\n",
      " - res: \"எருக்கூர் சிங்கநேர் இறையே எனினும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.209302, loss: 34.108482\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21354467.wav\n",
      " - src: \"துரும்பேனும் என்னிடத்தில் சொத்தில்லை நோயால்\"\n",
      " - res: \"தோன்றின் என்னிடத்தில் சொத்தில்லை நோயால் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.105263, loss: 34.093803\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21311128.wav\n",
      " - src: \"அடஞ்செய்யும் வைதிகம் பொருட்படுத் தாதே \"\n",
      " - res: \"அஞ்சியும் வைதிகம் பொருட்படுத் தாதே \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.121212, loss: 33.822929\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19294224.wav\n",
      " - src: \"கர்ச்சனை செய்வது கண்டதுண்டோ எனில்\"\n",
      " - res: \"கற்பனை செய்வது கண்டதுண்டோ எனில்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.179487, loss: 33.486347\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21380626.wav\n",
      " - src: \"உற்றேறி மூலிகையின் உண்மை அறிந்திடுவேன் \"\n",
      " - res: \"பட்டியல் மூலிகையின் உண்மை அறிந்திடுவேன் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.333333, CER: 0.176471, loss: 14.054666\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20576976.wav\n",
      " - src: \"தூரத்தில் வரக்கண்டு வீட்டிலொளிவார்\"\n",
      " - res: \"தூரத்தில் வரக் கண்டு நீட்டி கொளவார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.333333, CER: 0.357143, loss: 8.246308\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21294334.wav\n",
      " - src: \"ஓடப்பர் உயரப்பர் எல்லாம்மாறி\"\n",
      " - res: \"ஓப்பன் உயரப் பெல்லம் மாறி \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.219512, loss: 26.897669\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20382313.wav\n",
      " - src: \"ஆர்எதிர்ப்பார் அன்னையார் அன்பு வெறிதன்னை \"\n",
      " - res: \"ஆர் கதிர் பார் அன்னையார் கண்டு வெளி தன்னை \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.470588, loss: 22.788118\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21302913.wav\n",
      " - src: \"இலையேஉண விலையேகதி\"\n",
      " - res: \"நிறைய உணவினையே கதி \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.133333, loss: 24.668331\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395015.wav\n",
      " - src: \"உளம்துடித்தார் எனினும்அவர் உயிர்வாழ்கின்றார் \"\n",
      " - res: \"உலர் படித்தார் எனினும் அவர் உயிர் வாழ்கின்றார் \"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Output/wiki_commonvoicetrain_open_slr_output.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxAuu6wi9nJm"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "# !python -u DeepSpeech.py --noshow_progressbar \\\n",
    "#   --train_files '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/CommonVoiceTrainPlusOpenSLR.csv' \\\n",
    "#   --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "#   --dev_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Val.csv' \\\n",
    "#   --feature_cache '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/feature_cache' \\\n",
    "#   --learning_rate 0.0001 \\\n",
    "#   --train_batch_size 64 \\\n",
    "#   --dev_batch_size 64 \\\n",
    "#   --test_batch_size 64 \\\n",
    "#   --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "#   --export_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Export' \\\n",
    "#   --summary_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Summary' \\\n",
    "#   --n_hidden 1024 \\\n",
    "#   --dropout_rate 0.4 \\\n",
    "#   --epochs 100 \\\n",
    "#   --test_output_file '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Output/output.json' \\\n",
    "#   --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "#   --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "#   --log_level 0 \\\n",
    "#   --max_to_keep 10 \\\n",
    "#   --noearly_stop \\\n",
    "#   \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-yrhq5_cG1O"
   },
   "source": [
    "## Testing On News Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7552,
     "status": "ok",
     "timestamp": 1619097272649,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "qO1xKlfFcMrD",
    "outputId": "9c899461-5a0a-4d1e-83ac-66458566485f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |                           #                    | 26823 Elapsed Time: 0:00:02\n",
      "\n",
      "Saving top 49321 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 195652 words in total\n",
      "  It has 49321 unique words\n",
      "  Your top-49321 words are 100.0000 percent of all words\n",
      "  Your most common word \"என்று\" occurred 1263 times\n",
      "  The least common word in your top-k is \"வேலைச்\" with 1 times\n",
      "  The first word with 2 occurrences is \"வழங்குவோம்\" at place 24251\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x555571b6a000 @  0x7f85c735b1e7 0x55556fc33772 0x55556fbc7358 0x55556fba6290 0x55556fb92096 0x7f85c54f4bf7 0x55556fb93ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x555611002000 @  0x7f85c735b1e7 0x55556fc33772 0x55556fc1d7aa 0x55556fc1e1c8 0x55556fba62ad 0x55556fb92096 0x7f85c54f4bf7 0x55556fb93ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 195652 types 49324\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:591888 2:4036503040 3:7568443392\n",
      "tcmalloc: large alloc 7568449536 bytes == 0x555571a5c000 @  0x7f85c735b1e7 0x55556fc33772 0x55556fc1d7aa 0x55556fc1e1c8 0x55556fba684e 0x55556fb92096 0x7f85c54f4bf7 0x55556fb93ada\n",
      "tcmalloc: large alloc 4036509696 bytes == 0x5558247de000 @  0x7f85c735b1e7 0x55556fc33772 0x55556fc1d7aa 0x55556fc1e1c8 0x55556fba6c3d 0x55556fb92096 0x7f85c54f4bf7 0x55556fb93ada\n",
      "Statistics:\n",
      "1 49324 D1=0.734799 D2=1.13043 D3+=1.30243\n",
      "2 137267 D1=0.864856 D2=1.18867 D3+=1.65402\n",
      "3 28472/152406 D1=0.760257 D2=1.18158 D3+=2.57889\n",
      "Memory estimate for binary LM:\n",
      "type      kB\n",
      "probing 4970 assuming -p 1.5\n",
      "probing 5967 assuming -r models -p 1.5\n",
      "trie    2894 without quantization\n",
      "trie    2030 assuming -q 8 -b 8 quantization \n",
      "trie    2721 assuming -a 22 array pointer compression\n",
      "trie    1856 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:591888 2:2196272 3:569440\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "#####*************##################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:591888 2:2196272 3:569440\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15538196 kB\tVmRSS:2643300 kB\tRSSMax:2656776 kB\tuser:0.614806\tsys:1.40939\tCPU:2.02424\treal:2.3086\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/News_CommonVoiceTrain_OpenSLR.txt' --output_dir . \\\n",
    "  --top_k 49321 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3803,
     "status": "ok",
     "timestamp": 1619097285001,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "ELjqvjZvdKZJ",
    "outputId": "5975d9ed-c53b-40cb-aada-74f2d71bc709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "49321 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-49321.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340141,
     "status": "ok",
     "timestamp": 1619097632441,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "MoLxTiBJdKdM",
    "outputId": "bb6e6484-b663-4de8-e22b-5e6e3da513ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-22 13:14:57.978942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-22 13:14:57.979384: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a062cdf480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 13:14:57.979435: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 13:14:57.986811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 13:14:58.010971: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 13:14:58.011278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dfb948aa4d81): /proc/driver/nvidia/version does not exist\n",
      "I0422 13:14:59.377984 140706526582656 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "2021-04-22 13:15:01.529199: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of system memory.\n",
      "2021-04-22 13:15:04.199062: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of system memory.\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "Test epoch | Steps: 0 | Elapsed Time: 0:00:00                                   2021-04-22 13:15:05.922063: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 16566784 exceeds 10% of system memory.\n",
      "2021-04-22 13:15:06.351901: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 16566784 exceeds 10% of system memory.\n",
      "2021-04-22 13:15:06.496932: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 34340864 exceeds 10% of system memory.\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:05:25                                  \n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.269251, CER: 0.124681, loss: 28.240021\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.023256, loss: 64.841270\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21310586.wav\n",
      " - src: \"இந்தியாவின் தேசத்தந்தை மகாத்மா காந்தியடிகள்\"\n",
      " - res: \"இந்தியாவின் தேசத்தந்தை மகாத்மா காந்தியடிகள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.075157\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19183354.wav\n",
      " - src: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      " - res: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.044212\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21342637.wav\n",
      " - src: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      " - res: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 60.037903\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19535899.wav\n",
      " - src: \"கல்லில் நடந்தால்உன் கால்கடுக்கும் என்றுரைத்தான் \"\n",
      " - res: \"கல்லில் நடந்தால்உன் கால்கடுக்கும் என்றுரைத்தான் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 58.942009\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20565411.wav\n",
      " - src: \"ஒறுத்தார்க்கு ஒருநாளை இன்பம் பொறுத்தார்க்குப் பொன்றுந் துணையும் புகழ் \"\n",
      " - res: \"ஒறுத்தார்க்கு ஒருநாளை இன்பம் பொறுத்தார்க்குப் பொன்றுந் துணையும் புகழ் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.458163\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19093889.wav\n",
      " - src: \"சமுகத்தில் விண்ணப்பம் சாதித்தோம் என்றார் \"\n",
      " - res: \"சமுகத்தில் விண்ணப்பம் சாதித்தோம் என்றார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.445395\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20636626.wav\n",
      " - src: \"சாருலதா வந்திருக்கிறாங்களா \"\n",
      " - res: \"சாருலதா வந்திருக்கிறாங்களா \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.031250, loss: 9.444711\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21380609.wav\n",
      " - src: \"அடிமையாய் வாழோமே ஆண்மைதான் இன்றி\"\n",
      " - res: \"அடிமையாய் வாழோமே ஆண்மைதான் இன்றி \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.343233\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19305337.wav\n",
      " - src: \"அத்தனையும் கசப்பாள் \"\n",
      " - res: \"அத்தனையும் கசப்பாள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.043478, loss: 9.292212\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21380466.wav\n",
      " - src: \"தங்குரைக் கின்றான் அடி \"\n",
      " - res: \"தங்குரைக் கின்றான் அடி\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.478261, loss: 22.349543\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20066991.wav\n",
      " - src: \"வீட்டில் உலாவுகின்றான் \"\n",
      " - res: \"மீதில் உணவின் றார்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.200000, loss: 17.879814\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20590613.wav\n",
      " - src: \"நீராரும் தண்கடலில் கண்டெடுத்த நித்திலமே \"\n",
      " - res: \"நீராடும் தன் கடலில் கண்படைத்த நித்திய மே \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.750000, CER: 0.297872, loss: 36.876984\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21304473.wav\n",
      " - src: \"இளஞ்சிசுவும் பெற்றவளும் கொஞ்சுகின்றார் ஓர்பால் \"\n",
      " - res: \"லஞ்சம் பெற்ற வரும் கொஞ்சு கின்றார் ஒரு கால் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.155556, loss: 24.668331\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395015.wav\n",
      " - src: \"உளம்துடித்தார் எனினும்அவர் உயிர்வாழ்கின்றார் \"\n",
      " - res: \"உலகத் குடித்தார் எனினும் அவர் உயிர் வாழ்கின்றார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.583333, loss: 23.492517\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_22435893.wav\n",
      " - src: \"ஃபயர்ஃபாக்ஸ்\"\n",
      " - res: \"யார் பாக்கி \"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Output/news_commonvoicetrain_open_slr_output.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enbBD3yOcNIq"
   },
   "source": [
    "## Testing on Wiki + News Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292351,
     "status": "ok",
     "timestamp": 1619098879119,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "rotLmqy0djc0",
    "outputId": "c639e064-92ce-4723-cd1e-70be754d14b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |                   #                          | 1651302 Elapsed Time: 0:03:20\n",
      "\n",
      "Saving top 1309580 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 17865739 words in total\n",
      "  It has 1309580 unique words\n",
      "  Your top-1309580 words are 100.0000 percent of all words\n",
      "  Your most common word \"மற்றும்\" occurred 169910 times\n",
      "  The least common word in your top-k is \"நிலவரத்துக்கு\" with 1 times\n",
      "  The first word with 2 occurrences is \"வெங்கடகவி\" at place 530772\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x5555e276a000 @  0x7f7f0a3031e7 0x5555e134a772 0x5555e12de358 0x5555e12bd290 0x5555e12a9096 0x7f7f0849cbf7 0x5555e12aaada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x555681c02000 @  0x7f7f0a3031e7 0x5555e134a772 0x5555e13347aa 0x5555e13351c8 0x5555e12bd2ad 0x5555e12a9096 0x7f7f0849cbf7 0x5555e12aaada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 17865739 types 1309583\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:15714996 2:4031242752 3:7558580224\n",
      "tcmalloc: large alloc 7558586368 bytes == 0x5555e265c000 @  0x7f7f0a3031e7 0x5555e134a772 0x5555e13347aa 0x5555e13351c8 0x5555e12bd84e 0x5555e12a9096 0x7f7f0849cbf7 0x5555e12aaada\n",
      "tcmalloc: large alloc 4031250432 bytes == 0x5558953de000 @  0x7f7f0a3031e7 0x5555e134a772 0x5555e13347aa 0x5555e13351c8 0x5555e12bdc3d 0x5555e12a9096 0x7f7f0849cbf7 0x5555e12aaada\n",
      "Statistics:\n",
      "1 1309583 D1=0.705146 D2=1.02462 D3+=1.42125\n",
      "2 9283936 D1=0.846654 D2=1.1951 D3+=1.36859\n",
      "3 1002202/13750068 D1=0.907955 D2=1.35748 D3+=1.4795\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 262 assuming -p 1.5\n",
      "probing 320 assuming -r models -p 1.5\n",
      "trie    151 without quantization\n",
      "trie     96 assuming -q 8 -b 8 quantization \n",
      "trie    133 assuming -a 22 array pointer compression\n",
      "trie     78 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:15714996 2:148542976 3:20044040\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "*******#############################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:15714996 2:148542976 3:20044040\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15533056 kB\tVmRSS:3257988 kB\tRSSMax:3303944 kB\tuser:31.0983\tsys:10.6383\tCPU:41.7367\treal:52.5155\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Wiki_News_CommonVoiceTrain_OpenSLR.txt' --output_dir . \\\n",
    "  --top_k 1309580 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382560,
     "status": "ok",
     "timestamp": 1619098978115,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "VBA5sXgWdn7J",
    "outputId": "e49e6666-8d8c-4659-ff64-efff7a39c12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "1309580 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-1309580.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 730927,
     "status": "ok",
     "timestamp": 1619099330868,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "D98hghdTdoAp",
    "outputId": "9beb59f7-ae6b-419e-dd49-f5cc5996daef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-22 13:43:00.929374: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-22 13:43:00.929640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557d9188b480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 13:43:00.929679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 13:43:00.932657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 13:43:00.943749: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 13:43:00.943804: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dfb948aa4d81): /proc/driver/nvidia/version does not exist\n",
      "I0422 13:43:01.747291 139824410318720 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:05:44                                  \n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.369720, CER: 0.164440, loss: 28.240021\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.075157\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19183354.wav\n",
      " - src: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      " - res: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.044212\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21342637.wav\n",
      " - src: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      " - res: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 58.942009\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20565411.wav\n",
      " - src: \"ஒறுத்தார்க்கு ஒருநாளை இன்பம் பொறுத்தார்க்குப் பொன்றுந் துணையும் புகழ் \"\n",
      " - res: \"ஒறுத்தார்க்கு ஒருநாளை இன்பம் பொறுத்தார்க்குப் பொன்றுந் துணையும் புகழ் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 51.598667\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19533182.wav\n",
      " - src: \"எனைத்தானும் நல்லவை கேட்க அனைத்தானும் ஆன்ற பெருமை தரும் \"\n",
      " - res: \"எனைத்தானும் நல்லவை கேட்க அனைத்தானும் ஆன்ற பெருமை தரும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 50.231178\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20329519.wav\n",
      " - src: \"தாழ்வகற்ற எண்ணுங்கால் சாக்குருவி வேதாந்தம் \"\n",
      " - res: \"தாழ்வகற்ற எண்ணுங்கால் சாக்குருவி வேதாந்தம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.187500, loss: 34.856621\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21311809.wav\n",
      " - src: \"அங்குப் பாயினில் அயர்ந்து கிடந்த\"\n",
      " - res: \"கண்ட பாயினில் அயர்ந்து கிடந்த\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.090909, loss: 34.459393\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21302529.wav\n",
      " - src: \"ஊனுருகி ஒழியட்டும் எனவி டுத்தீர் \"\n",
      " - res: \"உருகி ஒழியட்டும் எனவி டுத்தீர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.176471, loss: 34.323708\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21277645.wav\n",
      " - src: \"இடிக்குரற் சிங்கநேர் இறையே எனினும்\"\n",
      " - res: \"எருக்கூர் சிங்கநேர் இறையே எனினும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.209302, loss: 34.108482\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21354467.wav\n",
      " - src: \"துரும்பேனும் என்னிடத்தில் சொத்தில்லை நோயால்\"\n",
      " - res: \"தோன்றின் என்னிடத்தில் சொத்தில்லை நோயால் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.250000, CER: 0.105263, loss: 34.093803\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21311128.wav\n",
      " - src: \"அடஞ்செய்யும் வைதிகம் பொருட்படுத் தாதே \"\n",
      " - res: \"அஞ்சியும் வைதிகம் பொருட்படுத் தாதே \"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.333333, CER: 0.357143, loss: 8.246308\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21294334.wav\n",
      " - src: \"ஓடப்பர் உயரப்பர் எல்லாம்மாறி\"\n",
      " - res: \"ஓப்பன் உயரப் பெல்லம் மாறி \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.219512, loss: 26.897669\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20382313.wav\n",
      " - src: \"ஆர்எதிர்ப்பார் அன்னையார் அன்பு வெறிதன்னை \"\n",
      " - res: \"ஆர் கதிர் பார் அன்னையார் கண்டு வெளி தன்னை \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.470588, loss: 22.788118\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21302913.wav\n",
      " - src: \"இலையேஉண விலையேகதி\"\n",
      " - res: \"நிறைய உணவினையே கதி \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.304348, loss: 19.391926\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19171536.wav\n",
      " - src: \"என்னென்று தானினைத்தாய் \"\n",
      " - res: \"என்னென்று சான் மலை தாய் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.133333, loss: 24.668331\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395015.wav\n",
      " - src: \"உளம்துடித்தார் எனினும்அவர் உயிர்வாழ்கின்றார் \"\n",
      " - res: \"உலர் படித்தார் எனினும் அவர் உயிர் வாழ்கின்றார் \"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Output/wikiandnews_commonvoicetrain_open_slr_output.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjPX5FG-cSBt"
   },
   "source": [
    "## Testing on CommonVoiceTrainPlusOpenSLR Text Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5271,
     "status": "ok",
     "timestamp": 1619099703528,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "06AVOCIqeZE0",
    "outputId": "fe159777-b43c-4226-e84c-77d9eac6be7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |         #                                      | 13439 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 20739 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 64905 words in total\n",
      "  It has 20739 unique words\n",
      "  Your top-20739 words are 100.0000 percent of all words\n",
      "  Your most common word \"என்று\" occurred 294 times\n",
      "  The least common word in your top-k is \"இருந்துவிடலாம்\" with 1 times\n",
      "  The first word with 2 occurrences is \"வலியுறுத்தினார்\" at place 14678\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x55df42610000 @  0x7f9b16dcd1e7 0x55df40be1772 0x55df40b75358 0x55df40b54290 0x55df40b40096 0x7f9b14f66bf7 0x55df40b41ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x55dfe1aa8000 @  0x7f9b16dcd1e7 0x55df40be1772 0x55df40bcb7aa 0x55df40bcc1c8 0x55df40b542ad 0x55df40b40096 0x7f9b14f66bf7 0x55df40b41ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 64905 types 20742\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:248904 2:4036622336 3:7568667136\n",
      "tcmalloc: large alloc 7568670720 bytes == 0x55df42502000 @  0x7f9b16dcd1e7 0x55df40be1772 0x55df40bcb7aa 0x55df40bcc1c8 0x55df40b5484e 0x55df40b40096 0x7f9b14f66bf7 0x55df40b41ada\n",
      "tcmalloc: large alloc 4036624384 bytes == 0x55e1f5284000 @  0x7f9b16dcd1e7 0x55df40be1772 0x55df40bcb7aa 0x55df40bcc1c8 0x55df40b54c3d 0x55df40b40096 0x7f9b14f66bf7 0x55df40b41ada\n",
      "Statistics:\n",
      "1 20742 D1=0.791036 D2=1.19167 D3+=1.51099\n",
      "2 37351 D1=0.819246 D2=1.14898 D3+=2.2172\n",
      "3 21658/35210 D1=0.312229 D2=1.62485 D3+=2.88551\n",
      "Memory estimate for binary LM:\n",
      "type      kB\n",
      "probing 1782 assuming -p 1.5\n",
      "probing 2082 assuming -r models -p 1.5\n",
      "trie    1031 without quantization\n",
      "trie     759 assuming -q 8 -b 8 quantization \n",
      "trie     991 assuming -a 22 array pointer compression\n",
      "trie     719 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:248904 2:597616 3:433160\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "#########################################********************#######################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:248904 2:597616 3:433160\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15538308 kB\tVmRSS:2636660 kB\tRSSMax:2654184 kB\tuser:0.356986\tsys:1.32427\tCPU:1.68132\treal:1.89827\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/CommonVoiceTrain_OpenSLR.txt' --output_dir . \\\n",
    "  --top_k 20739 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2414,
     "status": "ok",
     "timestamp": 1619099709310,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "1XUflOxWeZMQ",
    "outputId": "0c56ae6c-86bd-4616-8013-0becabcd78a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "20739 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-20739.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 326958,
     "status": "ok",
     "timestamp": 1619100044672,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "vG0Ol-IifiRz",
    "outputId": "f6824b98-5032-4eb2-ea75-a80116f46be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-22 13:55:21.167662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-22 13:55:21.167966: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f7b4123800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 13:55:21.168016: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 13:55:21.170434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 13:55:21.181904: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 13:55:21.181973: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dfb948aa4d81): /proc/driver/nvidia/version does not exist\n",
      "I0422 13:55:21.893901 139828680284032 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv\n",
      "Test epoch | Steps: 24 | Elapsed Time: 0:05:18                                  \n",
      "Test on /content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv - WER: 0.250826, CER: 0.117248, loss: 28.240021\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 79.816330\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19172119.wav\n",
      " - src: \"சொற்களைப் பொருள் புரிந்து காலத்திற்கு ஏற்றவாறு பயன்படுத்து \"\n",
      " - res: \"சொற்களைப் பொருள் புரிந்து காலத்திற்கு ஏற்றவாறு பயன்படுத்து \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.023256, loss: 64.841270\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21310586.wav\n",
      " - src: \"இந்தியாவின் தேசத்தந்தை மகாத்மா காந்தியடிகள்\"\n",
      " - res: \"இந்தியாவின் தேசத்தந்தை மகாத்மா காந்தியடிகள் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.075157\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19183354.wav\n",
      " - src: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      " - res: \"அளவறிந்து வாழாதான் வாழ்க்கை உளபோல இல்லாகி தோன்றாக் கெடும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 64.044212\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21342637.wav\n",
      " - src: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      " - res: \"கண்ணுடையர் என்பவர் கற்றோர் முகத்திரண்டு புண்ணுடையர் கல்லாதவர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 60.037903\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19535899.wav\n",
      " - src: \"கல்லில் நடந்தால்உன் கால்கடுக்கும் என்றுரைத்தான் \"\n",
      " - res: \"கல்லில் நடந்தால்உன் கால்கடுக்கும் என்றுரைத்தான் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.541513\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21328304.wav\n",
      " - src: \"இல்லை இல்லை என்றார் மைத்துனர் \"\n",
      " - res: \"இல்லை இல்லை என்றார் மைத்துனர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.484114\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_21386886.wav\n",
      " - src: \"சொந்தத் தாய்நாட்டுக்குச் சொன்னாள் பெருவாழ்த்து \"\n",
      " - res: \"சொந்தத் தாய்நாட்டுக்குச் சொன்னாள் பெருவாழ்த்து \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.441065\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_19523231.wav\n",
      " - src: \"நெஞ்சையும் வானத்தையும் குளிர் \"\n",
      " - res: \"நெஞ்சையும் வானத்தையும் குளிர் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.431662\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395392.wav\n",
      " - src: \"ஓடச்செய்தால் நமையும் ஓடச்செய்வார் என்பேன் \"\n",
      " - res: \"ஓடச்செய்தால் நமையும் ஓடச்செய்வார் என்பேன் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.033333, loss: 10.364573\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20394616.wav\n",
      " - src: \"உழுந்து கிடந்த ஒருகளம் போலவும்\"\n",
      " - res: \"உழுந்து கிடந்த ஒருகளம் போலவும் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.391304, loss: 22.349543\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20066991.wav\n",
      " - src: \"வீட்டில் உலாவுகின்றான் \"\n",
      " - res: \"மீதில் உணவு கின்றார்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.500000, CER: 0.200000, loss: 17.879814\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20590613.wav\n",
      " - src: \"நீராரும் தண்கடலில் கண்டெடுத்த நித்திலமே \"\n",
      " - res: \"நீராலும் தன் கடலில் கண்படைத்த நித்திய மே \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.666667, CER: 0.264706, loss: 14.054666\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20576976.wav\n",
      " - src: \"தூரத்தில் வரக்கண்டு வீட்டிலொளிவார்\"\n",
      " - res: \"படத்தில் வரத் கண்டு வீட்டி தெளிவார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.155556, loss: 24.668331\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_20395015.wav\n",
      " - src: \"உளம்துடித்தார் எனினும்அவர் உயிர்வாழ்கின்றார் \"\n",
      " - res: \"உலகக் குடித்தார் எனினும் அவர் உயிர் வாழ்கின்றார் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 2.000000, CER: 0.583333, loss: 23.492517\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Audio16000/common_voice_ta_22435893.wav\n",
      " - src: \"ஃபயர்ஃபாக்ஸ்\"\n",
      " - res: \"யார் பாக்கி \"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/My Drive/deepspeech/data/CommonVoiceTamil/Test.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Output/CommonVoiceTrainPlusOpenSLR.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245406,
     "status": "ok",
     "timestamp": 1619329816427,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "9wNG8ilfhgP2",
    "outputId": "c808479d-6d48-476f-9c94-776f1911d2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |            #                                 | 1637918 Elapsed Time: 0:02:44\n",
      "\n",
      "Saving top 1303210 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 17734992 words in total\n",
      "  It has 1303210 unique words\n",
      "  Your top-1303210 words are 100.0000 percent of all words\n",
      "  Your most common word \"மற்றும்\" occurred 169339 times\n",
      "  The least common word in your top-k is \"20107\" with 1 times\n",
      "  The first word with 2 occurrences is \"ஸ்ரீகுமாரின்\" at place 528162\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x55ce48a74000 @  0x7f59e64cc1e7 0x55ce46087772 0x55ce4601b358 0x55ce45ffa290 0x55ce45fe6096 0x7f59e4665bf7 0x55ce45fe7ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x55cee7f0c000 @  0x7f59e64cc1e7 0x55ce46087772 0x55ce460717aa 0x55ce460721c8 0x55ce45ffa2ad 0x55ce45fe6096 0x7f59e4665bf7 0x55ce45fe7ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 17734992 types 1303213\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:15638556 2:4031269376 3:7558630400\n",
      "tcmalloc: large alloc 7558635520 bytes == 0x55ce48966000 @  0x7f59e64cc1e7 0x55ce46087772 0x55ce460717aa 0x55ce460721c8 0x55ce45ffa84e 0x55ce45fe6096 0x7f59e4665bf7 0x55ce45fe7ada\n",
      "tcmalloc: large alloc 4031275008 bytes == 0x55d0fb6e8000 @  0x7f59e64cc1e7 0x55ce46087772 0x55ce460717aa 0x55ce460721c8 0x55ce45ffac3d 0x55ce45fe6096 0x7f59e4665bf7 0x55ce45fe7ada\n",
      "Statistics:\n",
      "1 1303213 D1=0.705136 D2=1.0251 D3+=1.42077\n",
      "2 9216617 D1=0.846745 D2=1.19547 D3+=1.36983\n",
      "3 993561/13642328 D1=0.907997 D2=1.35843 D3+=1.47874\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 260 assuming -p 1.5\n",
      "probing 318 assuming -r models -p 1.5\n",
      "trie    150 without quantization\n",
      "trie     95 assuming -q 8 -b 8 quantization \n",
      "trie    132 assuming -a 22 array pointer compression\n",
      "trie     78 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:15638556 2:147465872 3:19871220\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "*******#############################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:15638556 2:147465872 3:19871220\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:15533084 kB\tVmRSS:3253624 kB\tRSSMax:3299352 kB\tuser:23.0438\tsys:5.17923\tCPU:28.223\treal:35.3848\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Wiki_CommonVoiceTrain_OpenSLR.txt' --output_dir . \\\n",
    "  --top_k 1303210 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322591,
     "status": "ok",
     "timestamp": 1619329893631,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "pe1bSxuhhsHr",
    "outputId": "62d054d9-f75e-46f9-a226-948e6ee8921f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "1303210 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-1303210.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mk2SMixtjFCC"
   },
   "outputs": [],
   "source": [
    "! mkdir '/content/drive/MyDrive/deepspeech/data/TransferLearning/WikiOutput'\n",
    "\n",
    "! mkdir '/content/drive/MyDrive/deepspeech/data/TransferLearning/NewsOutput'\n",
    "\n",
    "! mkdir '/content/drive/MyDrive/deepspeech/data/TransferLearning/WikiNewsOutput'\n",
    "\n",
    "! mkdir '/content/drive/MyDrive/deepspeech/data/TransferLearning/CommonVoiceOpenSLROutput'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53394,
     "status": "ok",
     "timestamp": 1619330036703,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "NTBQ9J1bhgZ1",
    "outputId": "6a321dbb-b750-470f-9b81-c02fc5fcb5d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-25 05:53:09.889630: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-25 05:53:09.890099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a84c935480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-25 05:53:09.890146: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-25 05:53:09.896152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-25 05:53:10.110643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:10.111506: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a8503321c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-25 05:53:10.111540: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-04-25 05:53:10.112770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:10.113350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-25 05:53:10.150657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-25 05:53:10.403562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-25 05:53:10.524255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-25 05:53:10.546477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-25 05:53:10.814103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-25 05:53:10.835936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-25 05:53:11.339043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-25 05:53:11.339241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:11.340004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:11.340607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-25 05:53:11.344113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-25 05:53:11.346203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-25 05:53:11.346233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-25 05:53:11.346246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-25 05:53:11.347386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:11.348120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:11.348743: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-25 05:53:11.348830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I0425 05:53:12.885550 140602395355008 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "2021-04-25 05:53:14.762871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:14.763503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-25 05:53:14.763575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-25 05:53:14.763598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-25 05:53:14.763618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-25 05:53:14.763638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-25 05:53:14.763660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-25 05:53:14.763680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-25 05:53:14.763698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-25 05:53:14.763770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:14.764363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:14.764894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-25 05:53:14.764944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-25 05:53:14.764959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-25 05:53:14.764970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-25 05:53:14.765068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:14.765644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-25 05:53:14.766181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv\n",
      "Test epoch | Steps: 0 | Elapsed Time: 0:00:00                                   2021-04-25 05:53:25.181760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-25 05:53:46.859253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "Test epoch | Steps: 1 | Elapsed Time: 0:00:28                                   \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv - WER: 0.320000, CER: 0.223485, loss: 7.101742\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.547467\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/378.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.815082\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/410.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 7.498260\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/181.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.051867\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/19.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 6.581597\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/210.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 3.839622\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/416.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 3.718517\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/239.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 3.453496\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/372.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 3.167855\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/491.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 3.077619\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/375.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.600000, loss: 6.039838\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/357.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"போன்ற\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 5.945904\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/484.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.333333, loss: 5.520433\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/495.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழை\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 3.066265\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/73.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.400000, loss: 2.524021\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/363.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"அந்த\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/WikiOutput/output.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 64 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThC-ljbBhdqs"
   },
   "source": [
    "## Transfer Learning Speaker1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3406,
     "status": "ok",
     "timestamp": 1619370413747,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "ccekoJ96naRO",
    "outputId": "cb0783b1-8857-4372-e283-ae4f7b8459a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x559d89258000 @  0x7fa8302b21e7 0x559d87726772 0x559d876ba358 0x559d87699290 0x559d87685096 0x7fa82e44bbf7 0x559d87686ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x559e286f0000 @  0x7fa8302b21e7 0x559d87726772 0x559d877107aa 0x559d877111c8 0x559d876992ad 0x559d87685096 0x7fa82e44bbf7 0x559d87686ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036708864 3:7568829440\n",
      "tcmalloc: large alloc 7568834560 bytes == 0x559d8914a000 @  0x7fa8302b21e7 0x559d87726772 0x559d877107aa 0x559d877111c8 0x559d8769984e 0x559d87685096 0x7fa82e44bbf7 0x559d87686ada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x55a03becc000 @  0x7fa8302b21e7 0x559d87726772 0x559d877107aa 0x559d877111c8 0x559d87699c3d 0x559d87685096 0x7fa82e44bbf7 0x559d87686ada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538396 kB\tVmRSS:2632544 kB\tRSSMax:2640324 kB\tuser:0.217692\tsys:1.19831\tCPU:1.41604\treal:1.50382\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1346,
     "status": "ok",
     "timestamp": 1619370413748,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "xqyPi4EQnaUg",
    "outputId": "0de50b9f-70be-4c7b-ec8a-cd10c93ed50b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40803,
     "status": "ok",
     "timestamp": 1619371071033,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "mn2ZGQcenOfC",
    "outputId": "8b190827-e645-4165-a8d5-eabbe578241f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0425 17:17:13.090116 139752511256448 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 180.379719      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 47.261767       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 21.144004       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 16.894511       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 15.560805       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 14.307791       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 13.416455       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.947127       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.516068       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.160443       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:24.089074\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv\n",
      "Test epoch | Steps: 40 | Elapsed Time: 0:00:07                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv - WER: 0.075000, CER: 0.126168, loss: 7.076833\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 28.759224\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/110.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 13.732001\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/340.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.264908\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/119.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 8.970292\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/74.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 8.456483\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/2.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 5.433965\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/366.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.865780\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/352.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 4.524983\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/539.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.355061\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/285.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.237683\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/437.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 0.924031\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/50.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 0.923165\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/168.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 34.589481\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/261.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"ஒன்று \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 27.426764\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/396.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.825887\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/288.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Export/Speaker1Test\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Export/Speaker1Test/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Checkpoints/Speaker1Test' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Output/Speaker1Test/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/FeatureCache/Speaker1Test/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 1 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Export/Speaker1Test' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Summary/Speaker1Test' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88792,
     "status": "ok",
     "timestamp": 1619371184707,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "oD-cVjhB_Gsc",
    "outputId": "d7505d97-171d-4875-d16c-f20aedce18e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0425 17:18:18.818438 139992591939456 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 7 | Loss: 180.379803      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 47.261712       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 21.143959       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 16.894462       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 15.560775       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 14.307756       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 13.416445       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.947174       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.516047       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.160406       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:24.194892\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv\n",
      "Test epoch | Steps: 8 | Elapsed Time: 0:00:55                                   \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv - WER: 0.136000, CER: 0.195307, loss: 8.573269\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 32.278156\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/403.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 28.151432\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/260.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 25.646893\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/293.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 25.312111\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/54.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 25.202909\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/5.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.800704\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/338.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 4.761668\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/381.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.752374\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/49.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.745154\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/461.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.735702\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/475.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 4.513894\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/344.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 4.411370\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/27.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 4.055587\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/135.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 3.634001\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/164.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 3.466207\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/104.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Export/Speaker1Train\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Export/Speaker1Train/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Checkpoints/Speaker1Train' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Output/Speaker1Train/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/FeatureCache/Speaker1Train/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 64 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Export/Speaker1Train' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Summary/Speaker1Train' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ0b2lnH6wAz"
   },
   "source": [
    "## Transfer Learning Speaker2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201869,
     "status": "ok",
     "timestamp": 1619369434304,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "6GoYcsfN6zi6",
    "outputId": "7efd9b73-acf0-49bc-e9b2-fd899503cbb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x557503fc8000 @  0x7f94a1d081e7 0x557502f8d772 0x557502f21358 0x557502f00290 0x557502eec096 0x7f949fea1bf7 0x557502eedada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x5575a3460000 @  0x7f94a1d081e7 0x557502f8d772 0x557502f777aa 0x557502f781c8 0x557502f002ad 0x557502eec096 0x7f949fea1bf7 0x557502eedada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036708864 3:7568829440\n",
      "tcmalloc: large alloc 7568834560 bytes == 0x557503eba000 @  0x7f94a1d081e7 0x557502f8d772 0x557502f777aa 0x557502f781c8 0x557502f0084e 0x557502eec096 0x7f949fea1bf7 0x557502eedada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x5577b6c3c000 @  0x7f94a1d081e7 0x557502f8d772 0x557502f777aa 0x557502f781c8 0x557502f00c3d 0x557502eec096 0x7f949fea1bf7 0x557502eedada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538396 kB\tVmRSS:2632772 kB\tRSSMax:2644448 kB\tuser:0.220711\tsys:1.11473\tCPU:1.33548\treal:1.47648\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200702,
     "status": "ok",
     "timestamp": 1619369434847,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "7V9Bf_e06zoL",
    "outputId": "8720b68d-6892-4c91-fa67-bbdc4043a254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79987,
     "status": "ok",
     "timestamp": 1619371483860,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "6PI84FI76zrx",
    "outputId": "97c4929f-7165-4592-ff91-d6b3e1f733d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0425 17:23:54.557508 140564880369536 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 7 | Loss: 180.379782      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 47.261774       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 21.144023       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 16.894465       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 15.560764       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 14.307760       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 13.416378       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.947198       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.516047       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.160319       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:24.603439\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv\n",
      "Test epoch | Steps: 60 | Elapsed Time: 0:00:19                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv - WER: 0.233333, CER: 0.172840, loss: 13.754828\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 30.254839\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/55.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 25.905611\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/51.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 24.056938\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/54.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 22.334839\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/53.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 21.718853\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/52.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 10.560556\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/5.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.468583\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/9.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.280015\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/27.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.270951\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/14.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.000226\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/47.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 10.366676\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/26.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 8.206315\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/8.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.847466\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/3.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.279685\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/28.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 6.453996\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/11.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/Export\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/Export/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/Checkpoints' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/Output/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/FeatureCache/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 1 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/Export' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/Summary' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZWWRBIj6wem"
   },
   "source": [
    "## Transfer Learning Speaker3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70864,
     "status": "ok",
     "timestamp": 1619369506536,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "7gbpSqf360M7",
    "outputId": "8c049e57-d42a-4ce5-8f86-669b862f486d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x556cfec18000 @  0x7f38c00651e7 0x556cfd02d772 0x556cfcfc1358 0x556cfcfa0290 0x556cfcf8c096 0x7f38be1febf7 0x556cfcf8dada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x556d9e0b0000 @  0x7f38c00651e7 0x556cfd02d772 0x556cfd0177aa 0x556cfd0181c8 0x556cfcfa02ad 0x556cfcf8c096 0x7f38be1febf7 0x556cfcf8dada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036708864 3:7568829440\n",
      "tcmalloc: large alloc 7568834560 bytes == 0x556cfeb0a000 @  0x7f38c00651e7 0x556cfd02d772 0x556cfd0177aa 0x556cfd0181c8 0x556cfcfa084e 0x556cfcf8c096 0x7f38be1febf7 0x556cfcf8dada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x556fb188c000 @  0x7f38c00651e7 0x556cfd02d772 0x556cfd0177aa 0x556cfd0181c8 0x556cfcfa0c3d 0x556cfcf8c096 0x7f38be1febf7 0x556cfcf8dada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538392 kB\tVmRSS:2632604 kB\tRSSMax:2644440 kB\tuser:0.187236\tsys:1.17549\tCPU:1.36275\treal:1.48089\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70862,
     "status": "ok",
     "timestamp": 1619369506537,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "Ac7_9mAz60Qv",
    "outputId": "ffde7a2b-0171-4ec7-a468-7fb4b8cab8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43690,
     "status": "ok",
     "timestamp": 1619371527579,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "VipRG3mG60T6",
    "outputId": "37d22ee6-2621-4d02-a00e-25d999f10941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0425 17:24:47.149665 140186486503296 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 7 | Loss: 180.379656      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 47.261929       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 21.144000       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 16.894649       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 15.560948       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 14.307840       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 13.416461       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.947153       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.516126       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:01 | Steps: 7 | Loss: 12.160547       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:24.705599\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv\n",
      "Test epoch | Steps: 60 | Elapsed Time: 0:00:10                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv - WER: 0.050000, CER: 0.108974, loss: 9.720225\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 28.325100\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/11.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.200000, loss: 24.657738\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/28.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 24.045185\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/31.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 23.825850\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/24.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 19.682833\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/2.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.322341\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/6.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.164310\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/23.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.571328\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/12.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.014627\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/9.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 6.663802\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/34.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 1.902745\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/30.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 1.564955\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/13.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 18.291607\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/43.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.333333, loss: 14.654126\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/42.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 6.909765\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/18.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/Export\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/Export/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/Checkpoints' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/Output/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/FeatureCache/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 1 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/Export' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/Summary' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btlwJs5VIwZk"
   },
   "source": [
    "## Digit Recognition Testing on Trained Model for Speaker1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6035,
     "status": "ok",
     "timestamp": 1619423994006,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "o_WW6ZpJJI0u",
    "outputId": "b75e0753-e650-4480-8452-9743350bf805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x55e88fc0a000 @  0x7ff5cb1861e7 0x55e88d53d772 0x55e88d4d1358 0x55e88d4b0290 0x55e88d49c096 0x7ff5c931fbf7 0x55e88d49dada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x55e92f0a2000 @  0x7ff5cb1861e7 0x55e88d53d772 0x55e88d5277aa 0x55e88d5281c8 0x55e88d4b02ad 0x55e88d49c096 0x7ff5c931fbf7 0x55e88d49dada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036707328 3:7568826368\n",
      "tcmalloc: large alloc 7568826368 bytes == 0x55e88fafc000 @  0x7ff5cb1861e7 0x55e88d53d772 0x55e88d5277aa 0x55e88d5281c8 0x55e88d4b084e 0x55e88d49c096 0x7ff5c931fbf7 0x55e88d49dada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x55eb4287e000 @  0x7ff5cb1861e7 0x55e88d53d772 0x55e88d5277aa 0x55e88d5281c8 0x55e88d4b0c3d 0x55e88d49c096 0x7ff5c931fbf7 0x55e88d49dada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538396 kB\tVmRSS:2632620 kB\tRSSMax:2644480 kB\tuser:0.195941\tsys:1.08911\tCPU:1.28509\treal:1.46686\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7568,
     "status": "ok",
     "timestamp": 1619423995559,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "cCdSh_5EKvuE",
    "outputId": "55a9cf32-5dc9-4808-87fa-8c471bba67e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48983,
     "status": "ok",
     "timestamp": 1619424036986,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "uVUDVL8AKv0s",
    "outputId": "d5029b79-569e-48c0-cc5b-d8bd97e0c0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-26 08:00:00.525605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-26 08:00:00.525982: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d441153800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-26 08:00:00.526022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-26 08:00:00.616595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-26 08:00:00.808632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:00.809441: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d444a00540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-26 08:00:00.809496: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-04-26 08:00:00.810496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:00.811018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-26 08:00:00.821288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:00:01.058371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:00:01.180032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-26 08:00:01.216919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-26 08:00:01.462218: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-26 08:00:01.513069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-26 08:00:02.013740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-26 08:00:02.013919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:02.014650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:02.015186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-26 08:00:02.018170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:00:02.020256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-26 08:00:02.020288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-26 08:00:02.020299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-26 08:00:02.021234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:02.021851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:02.022413: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-26 08:00:02.022466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I0426 08:00:03.379594 140705698682752 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "2021-04-26 08:00:05.172278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:05.172921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-26 08:00:05.173009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:00:05.173031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:00:05.173050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-26 08:00:05.173068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-26 08:00:05.173109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-26 08:00:05.173142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-26 08:00:05.173160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-26 08:00:05.173235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:05.173853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:05.174420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-26 08:00:05.174491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-26 08:00:05.174505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-26 08:00:05.174515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-26 08:00:05.174617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:05.175163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:00:05.175694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv\n",
      "Test epoch | Steps: 0 | Elapsed Time: 0:00:00                                   2021-04-26 08:00:15.606289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:00:17.685913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "Test epoch | Steps: 40 | Elapsed Time: 0:00:18                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv - WER: 0.075000, CER: 0.126168, loss: 7.076834\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 28.759228\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/110.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 13.732001\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/340.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.264910\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/119.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 8.970295\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/74.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 8.456484\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/2.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 5.433967\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/366.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.865779\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/352.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 4.524985\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/539.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.355059\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/285.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.237683\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/437.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 0.924030\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/50.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 0.923165\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/168.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 34.589481\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/261.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"ஒன்று \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 27.426764\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/396.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.825887\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/288.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/Output/Speaker1Test/trained_model_output.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 1 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJk0ARrxIwj-"
   },
   "source": [
    "## Digit Recognition Testing on Trained Model for Speaker2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2953,
     "status": "ok",
     "timestamp": 1619424101978,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "-20e29gZMTeI",
    "outputId": "03894ee0-b807-43e7-895f-d378cdbb5226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x5571fa0ac000 @  0x7f93c7caf1e7 0x5571f7585772 0x5571f7519358 0x5571f74f8290 0x5571f74e4096 0x7f93c5e48bf7 0x5571f74e5ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x557299544000 @  0x7f93c7caf1e7 0x5571f7585772 0x5571f756f7aa 0x5571f75701c8 0x5571f74f82ad 0x5571f74e4096 0x7f93c5e48bf7 0x5571f74e5ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036707328 3:7568826368\n",
      "tcmalloc: large alloc 7568826368 bytes == 0x5571f9f9e000 @  0x7f93c7caf1e7 0x5571f7585772 0x5571f756f7aa 0x5571f75701c8 0x5571f74f884e 0x5571f74e4096 0x7f93c5e48bf7 0x5571f74e5ada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x5574acd20000 @  0x7f93c7caf1e7 0x5571f7585772 0x5571f756f7aa 0x5571f75701c8 0x5571f74f8c3d 0x5571f74e4096 0x7f93c5e48bf7 0x5571f74e5ada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538392 kB\tVmRSS:2632436 kB\tRSSMax:2644300 kB\tuser:0.240056\tsys:1.12326\tCPU:1.36336\treal:1.45377\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3203,
     "status": "ok",
     "timestamp": 1619424102420,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "RZes6jmXMTow",
    "outputId": "9015bfed-d380-4fba-a80d-cd5f825f76f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33647,
     "status": "ok",
     "timestamp": 1619424133514,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "rLoE1WkjMTwo",
    "outputId": "f32a1320-1f85-4f76-d11f-b602e458f9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-26 08:01:43.344202: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-26 08:01:43.344438: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0d2df9480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-26 08:01:43.344474: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-26 08:01:43.346112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-26 08:01:43.483202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:43.483994: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0d67f21c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-26 08:01:43.484027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-04-26 08:01:43.484213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:43.484857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-26 08:01:43.485164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:01:43.486647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:01:43.488188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-26 08:01:43.488589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-26 08:01:43.490088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-26 08:01:43.490740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-26 08:01:43.493640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-26 08:01:43.493741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:43.494397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:43.494965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-26 08:01:43.495039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:01:43.496022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-26 08:01:43.496048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-26 08:01:43.496058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-26 08:01:43.496194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:43.496808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:43.497318: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-26 08:01:43.497372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I0426 08:01:44.048209 140647167674240 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "2021-04-26 08:01:44.939199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:44.939841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-26 08:01:44.939919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:01:44.939942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:01:44.939960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-26 08:01:44.939978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-26 08:01:44.939999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-26 08:01:44.940018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-26 08:01:44.940036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-26 08:01:44.940109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:44.940689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:44.941179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-26 08:01:44.941225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-26 08:01:44.941239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-26 08:01:44.941248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-26 08:01:44.941344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:44.941905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:01:44.942429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv\n",
      "Test epoch | Steps: 0 | Elapsed Time: 0:00:00                                   2021-04-26 08:01:45.837667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:01:46.776458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-26 08:01:47.499201: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 6 | Elapsed Time: 0:00:03                                   2021-04-26 08:01:49.377027: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 12 | Elapsed Time: 0:00:06                                  2021-04-26 08:01:52.072315: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 17 | Elapsed Time: 0:00:07                                  2021-04-26 08:01:53.616609: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 25 | Elapsed Time: 0:00:10                                  2021-04-26 08:01:55.988840: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 35 | Elapsed Time: 0:00:13                                  2021-04-26 08:01:59.463335: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 39 | Elapsed Time: 0:00:14                                  2021-04-26 08:02:01.129548: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "2021-04-26 08:02:01.655387: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 42 | Elapsed Time: 0:00:19                                  2021-04-26 08:02:05.576055: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 52 | Elapsed Time: 0:00:22                                  2021-04-26 08:02:08.392774: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:153] Missing 2 bands  starting at 1 in mel-frequency design. Perhaps too many channels or not enough frequency resolution in spectrum. (input_length: 257 input_sample_rate: 44100 output_channel_count: 40 lower_frequency_limit: 20 upper_frequency_limit: 8000\n",
      "Test epoch | Steps: 60 | Elapsed Time: 0:00:25                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv - WER: 0.233333, CER: 0.172840, loss: 13.754828\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 30.254843\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/55.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 25.905613\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/51.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 24.056940\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/54.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 22.334835\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/53.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 21.718863\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/52.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 10.560557\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/5.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.468583\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/9.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.280014\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/27.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.270948\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/14.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.000226\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/47.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 10.366678\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/26.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 8.206316\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/8.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.847467\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/3.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.279683\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/28.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 6.453996\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/11.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/Output/trained_model_output.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 1 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUwaPqGfIwwD"
   },
   "source": [
    "## Digit Recognition Testing on Trained Model for Speaker3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3373,
     "status": "ok",
     "timestamp": 1619424136893,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "u80AbQtPMx9H",
    "outputId": "23a1c019-c94a-436f-e06c-48a143a824e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x565430f1a000 @  0x7ff69c2831e7 0x56542f988772 0x56542f91c358 0x56542f8fb290 0x56542f8e7096 0x7ff69a41cbf7 0x56542f8e8ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x5654d03b2000 @  0x7ff69c2831e7 0x56542f988772 0x56542f9727aa 0x56542f9731c8 0x56542f8fb2ad 0x56542f8e7096 0x7ff69a41cbf7 0x56542f8e8ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036707328 3:7568826368\n",
      "tcmalloc: large alloc 7568826368 bytes == 0x565430e0c000 @  0x7ff69c2831e7 0x56542f988772 0x56542f9727aa 0x56542f9731c8 0x56542f8fb84e 0x56542f8e7096 0x7ff69a41cbf7 0x56542f8e8ada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x5656e3b8e000 @  0x7ff69c2831e7 0x56542f988772 0x56542f9727aa 0x56542f9731c8 0x56542f8fbc3d 0x56542f8e7096 0x7ff69a41cbf7 0x56542f8e8ada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538396 kB\tVmRSS:2632348 kB\tRSSMax:2633992 kB\tuser:0.186921\tsys:1.07855\tCPU:1.26551\treal:1.40528\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1215,
     "status": "ok",
     "timestamp": 1619424158326,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "dz3-YCjVMyes",
    "outputId": "59a67cb0-f318-4379-f4f3-07142da8034f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24821,
     "status": "ok",
     "timestamp": 1619424191554,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "bD4q-P4CMyvB",
    "outputId": "ec0f60f6-2bf1-46e8-a0a5-44cad57bb4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "2021-04-26 08:02:48.402712: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-26 08:02:48.402928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bd60b07480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-26 08:02:48.402959: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-26 08:02:48.405691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-26 08:02:48.534883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:48.535624: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bd645001c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-26 08:02:48.535667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-04-26 08:02:48.535837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:48.536381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-26 08:02:48.536664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:02:48.538043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:02:48.539523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-26 08:02:48.539838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-26 08:02:48.541185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-26 08:02:48.541825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-26 08:02:48.544614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-26 08:02:48.544715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:48.545270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:48.545784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-26 08:02:48.545840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:02:48.546827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-26 08:02:48.546853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-26 08:02:48.546864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-26 08:02:48.546971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:48.547612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:48.548146: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-04-26 08:02:48.548189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I0426 08:02:49.086808 140476820793216 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "2021-04-26 08:02:49.953418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:49.954027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-04-26 08:02:49.954098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-04-26 08:02:49.954121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:02:49.954142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-26 08:02:49.954162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-26 08:02:49.954185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-04-26 08:02:49.954203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-04-26 08:02:49.954222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-04-26 08:02:49.954299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:49.954887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:49.955394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-04-26 08:02:49.955441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-26 08:02:49.955456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-04-26 08:02:49.955466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-04-26 08:02:49.955588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:49.956136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-26 08:02:49.956666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv\n",
      "Test epoch | Steps: 0 | Elapsed Time: 0:00:00                                   2021-04-26 08:02:50.843432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-04-26 08:02:51.653293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "Test epoch | Steps: 60 | Elapsed Time: 0:00:18                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv - WER: 0.050000, CER: 0.108974, loss: 9.720225\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 28.325102\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/11.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.200000, loss: 24.657740\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/28.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 24.045181\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/31.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 23.825842\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/24.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 19.682833\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/2.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.322342\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/6.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.164310\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/23.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.571324\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/12.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.014630\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/9.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 6.663801\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/34.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 1.902744\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/30.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 1.564953\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/13.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 18.291616\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/43.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.333333, loss: 14.654125\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/42.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 6.909764\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/18.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "!python evaluate.py \\\n",
    "  --test_files '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv' \\\n",
    "  --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/Output/trained_model_output.json' \\\n",
    "  --checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "  --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "  --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "  --n_hidden 1024 \\\n",
    "  --test_batch_size 1 \\\n",
    "  \"$@\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mn75UukDIw5w"
   },
   "source": [
    "## TransferLearning with Spec Argument for Speaker1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3204,
     "status": "ok",
     "timestamp": 1619425262135,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "UGfXDrXsPP_B",
    "outputId": "056b4de4-f1ad-418d-ed33-624c08f6bb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x55e13e22e000 @  0x7f6ea35801e7 0x55e13b6f8772 0x55e13b68c358 0x55e13b66b290 0x55e13b657096 0x7f6ea1719bf7 0x55e13b658ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x55e1dd6c6000 @  0x7f6ea35801e7 0x55e13b6f8772 0x55e13b6e27aa 0x55e13b6e31c8 0x55e13b66b2ad 0x55e13b657096 0x7f6ea1719bf7 0x55e13b658ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036707328 3:7568826368\n",
      "tcmalloc: large alloc 7568826368 bytes == 0x55e13e120000 @  0x7f6ea35801e7 0x55e13b6f8772 0x55e13b6e27aa 0x55e13b6e31c8 0x55e13b66b84e 0x55e13b657096 0x7f6ea1719bf7 0x55e13b658ada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x55e3f0ea2000 @  0x7f6ea35801e7 0x55e13b6f8772 0x55e13b6e27aa 0x55e13b6e31c8 0x55e13b66bc3d 0x55e13b657096 0x7f6ea1719bf7 0x55e13b658ada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538392 kB\tVmRSS:2632396 kB\tRSSMax:2644320 kB\tuser:0.210634\tsys:1.16199\tCPU:1.37266\treal:1.50934\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2171,
     "status": "ok",
     "timestamp": 1619425262586,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "dYISFLlcPQIw",
    "outputId": "4883197c-3a1d-43f7-adeb-0be84bbaf187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55995,
     "status": "ok",
     "timestamp": 1619426209211,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "u0wzz5LhPO8Z",
    "outputId": "29867c03-97c8-4991-a77b-8493a5e80249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W Due to current feature-cache settings the exact same sample augmentations of the first epoch will be repeated on all following epochs. This could lead to unintended over-fitting. You could use --cache_for_epochs <n_epochs> to invalidate the cache after a given number of epochs.\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0426 08:35:55.661146 140197531162496 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 7 | Loss: 182.720428      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 47.191734       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 21.304368       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 16.934834       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 15.666673       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 14.349385       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 13.453710       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.798189       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.222554       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 11.857964       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:38.004151\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv\n",
      "Test epoch | Steps: 40 | Elapsed Time: 0:00:08                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv - WER: 0.075000, CER: 0.126168, loss: 7.076834\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 28.759228\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/110.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 13.732001\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/340.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 9.264910\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/119.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 8.970295\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/74.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 8.456484\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/2.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 5.433967\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/366.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.865779\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/352.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 4.524985\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/539.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.355059\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/285.wav\n",
      " - src: \"இரண்டு\"\n",
      " - res: \"இரண்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.237683\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/437.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 0.924030\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/50.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 0.923165\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/168.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 34.589481\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/261.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"ஒன்று \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 27.426764\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/396.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.825887\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/288.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentExport/Speaker1Test\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentExport/Speaker1Test/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentCheckpoints/Speaker1Test' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentOutput/Speaker1Test/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentFeatureCache/Speaker1Test/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTest.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 1 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentExport/Speaker1Test' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentSummary/Speaker1Test' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\\n",
    "    --augment pitch[p=0.1,pitch=1~0.2] \\\n",
    "    --augment tempo[p=0.1,factor=1~0.5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103428,
     "status": "ok",
     "timestamp": 1619426415624,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "Otl6XnkhQ5FS",
    "outputId": "f2a0d911-0c47-4aa4-be2e-91664a677106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W Due to current feature-cache settings the exact same sample augmentations of the first epoch will be repeated on all following epochs. This could lead to unintended over-fitting. You could use --cache_for_epochs <n_epochs> to invalidate the cache after a given number of epochs.\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0426 08:38:34.578899 140071066417024 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 7 | Loss: 182.720280      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 47.191681       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 21.304365       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 16.934869       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 15.666684       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 14.349327       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 13.453672       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.798124       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.222543       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 11.857853       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:36.028128\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv\n",
      "Test epoch | Steps: 8 | Elapsed Time: 0:00:57                                   \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv - WER: 0.136000, CER: 0.195307, loss: 8.573269\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 32.278152\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/403.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 28.151436\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/260.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 25.646898\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/293.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 25.312103\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/54.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 25.202908\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/5.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.800704\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/338.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 4.761666\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/381.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.752377\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/49.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.745152\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/461.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 4.735700\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/475.wav\n",
      " - src: \"ஒன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 4.513894\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/344.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 4.411372\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/27.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 4.055586\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/135.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 3.634002\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/164.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 3.466208\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/104.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentExport/Speaker1Train\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentExport/Speaker1Train/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentCheckpoints/Speaker1Train' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentOutput/Speaker1Train/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentFeatureCache/Speaker1Train/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 64 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentExport/Speaker1Train' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker1/SpecAugmentSummary/Speaker1Train' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\\n",
    "    --augment pitch[p=0.1,pitch=1~0.2] \\\n",
    "    --augment tempo[p=0.1,factor=1~0.5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqgfA_NyJGaQ"
   },
   "source": [
    "## TransferLearning with Spec Argument for Speaker2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3292,
     "status": "ok",
     "timestamp": 1619425810656,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "Hz1CA3tVPUpM",
    "outputId": "4033ea15-e4a3-47fc-e24f-1c24a8ac3a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x55a739b88000 @  0x7f624f2d51e7 0x55a737721772 0x55a7376b5358 0x55a737694290 0x55a737680096 0x7f624d46ebf7 0x55a737681ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x55a7d9020000 @  0x7f624f2d51e7 0x55a737721772 0x55a73770b7aa 0x55a73770c1c8 0x55a7376942ad 0x55a737680096 0x7f624d46ebf7 0x55a737681ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036707328 3:7568826368\n",
      "tcmalloc: large alloc 7568826368 bytes == 0x55a739a7a000 @  0x7f624f2d51e7 0x55a737721772 0x55a73770b7aa 0x55a73770c1c8 0x55a73769484e 0x55a737680096 0x7f624d46ebf7 0x55a737681ada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x55a9ec7fc000 @  0x7f624f2d51e7 0x55a737721772 0x55a73770b7aa 0x55a73770c1c8 0x55a737694c3d 0x55a737680096 0x7f624d46ebf7 0x55a737681ada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538396 kB\tVmRSS:2632548 kB\tRSSMax:2644404 kB\tuser:0.20793\tsys:1.15261\tCPU:1.36058\treal:1.45511\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1515,
     "status": "ok",
     "timestamp": 1619425820290,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "APrhKkoRPWr4",
    "outputId": "f0a640ca-dc1a-442b-8942-ba349b4cd4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63162,
     "status": "ok",
     "timestamp": 1619426506217,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "RGeqawRqPX_P",
    "outputId": "949d1996-18e4-4524-846d-3b131cd388b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W Due to current feature-cache settings the exact same sample augmentations of the first epoch will be repeated on all following epochs. This could lead to unintended over-fitting. You could use --cache_for_epochs <n_epochs> to invalidate the cache after a given number of epochs.\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0426 08:40:45.408005 140240555800448 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 7 | Loss: 180.379741      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 47.261897       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 21.143932       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 16.894591       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 15.560674       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 14.307712       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 13.416345       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.947317       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.516188       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.160579       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:33.649733\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv\n",
      "Test epoch | Steps: 60 | Elapsed Time: 0:00:20                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv - WER: 0.233333, CER: 0.172840, loss: 13.754828\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 30.254843\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/55.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 25.905613\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/51.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 24.056940\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/54.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 22.334835\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/53.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 21.718863\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/52.wav\n",
      " - src: \"ஒன்பது\"\n",
      " - res: \"ஒன்பது\"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 10.560557\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/5.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.468583\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/9.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.280014\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/27.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.270948\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/14.wav\n",
      " - src: \"ஐந்து\"\n",
      " - res: \"ஐந்து\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 10.000226\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/47.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 10.366678\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/26.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 8.206316\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/8.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.847467\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/3.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 7.279683\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/28.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 6.453996\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker2/11.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/SpecAugmentExport\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/SpecAugmentExport/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/SpecAugmentCheckpoints' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/SpecAugmentOutput/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/SpecAugmentFeatureCache/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 1 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/SpecAugmentExport' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker2/SpecAugmentSummary' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\\n",
    "    --augment pitch[p=0.1,pitch=1~0.2] \\\n",
    "    --augment tempo[p=0.1,factor=1~0.5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gG0lE7i8JHX2"
   },
   "source": [
    "## TransferLearning with Spec Argument for Speaker3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3371,
     "status": "ok",
     "timestamp": 1619426519686,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "NGxcwYIMPVSD",
    "outputId": "491cb8ee-37d2-4816-8622-675763701f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "\n",
      "Converting to lowercase and counting word occurrences ...\n",
      "| |#                                                   | 9 Elapsed Time: 0:00:00\n",
      "\n",
      "Saving top 10 words ...\n",
      "\n",
      "Calculating word statistics ...\n",
      "  Your text file has 10 words in total\n",
      "  It has 10 unique words\n",
      "  Your top-10 words are 100.0000 percent of all words\n",
      "  Your most common word \"இரண்டு\" occurred 1 times\n",
      "  The least common word in your top-k is \"ஒன்பது\" with 1 times\n",
      "\n",
      "Creating ARPA file ...\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/drive/My Drive/deepspeech/data/lm/lower.txt.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2672394240 bytes == 0x56138a87e000 @  0x7f56d46cc1e7 0x561388f14772 0x561388ea8358 0x561388e87290 0x561388e73096 0x7f56d2865bf7 0x561388e74ada\n",
      "tcmalloc: large alloc 8907980800 bytes == 0x561429d16000 @  0x7f56d46cc1e7 0x561388f14772 0x561388efe7aa 0x561388eff1c8 0x561388e872ad 0x561388e73096 0x7f56d2865bf7 0x561388e74ada\n",
      "****************************************************************************************************\n",
      "Unigram tokens 10 types 13\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:156 2:4036707328 3:7568826368\n",
      "tcmalloc: large alloc 7568826368 bytes == 0x56138a770000 @  0x7f56d46cc1e7 0x561388f14772 0x561388efe7aa 0x561388eff1c8 0x561388e8784e 0x561388e73096 0x7f56d2865bf7 0x561388e74ada\n",
      "tcmalloc: large alloc 4036714496 bytes == 0x56163d4f2000 @  0x7f56d46cc1e7 0x561388f14772 0x561388efe7aa 0x561388eff1c8 0x561388e87c3d 0x561388e73096 0x7f56d2865bf7 0x561388e74ada\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 13 D1=0.5 D2=1 D3+=1.5\n",
      "2 19 D1=0.5 D2=1 D3+=1.5\n",
      "3 0/9 D1=0.5 D2=1 D3+=1.5\n",
      "Memory estimate for binary LM:\n",
      "type       B\n",
      "probing  808 assuming -p 1.5\n",
      "probing  976 assuming -r models -p 1.5\n",
      "trie     541 without quantization\n",
      "trie    3500 assuming -q 8 -b 8 quantization \n",
      "trie     564 assuming -a 22 array pointer compression\n",
      "trie    3523 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:156 2:304 3:20\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "\n",
      "Name:lmplz\tVmPeak:15538396 kB\tVmRSS:2632500 kB\tRSSMax:2644412 kB\tuser:0.190571\tsys:1.15141\tCPU:1.34202\treal:1.47634\n",
      "\n",
      "Filtering ARPA file using vocabulary of top-k words ...\n",
      "Reading ./lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "\n",
      "Building lm.binary ...\n",
      "Reading ./lm_filtered.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Identifying n-grams omitted by SRI\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Quantizing\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Writing trie\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "\n",
    "! python3 generate_lm.py --input_txt '/content/drive/MyDrive/deepspeech/data/TransferLearning/vocab.txt' --output_dir . \\\n",
    "  --top_k 10 --kenlm_bins '/content/drive/My Drive/kenlm/build/bin' \\\n",
    "  --arpa_order 3 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\" \\\n",
    "  --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3137,
     "status": "ok",
     "timestamp": 1619426520141,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "9jiSNn-aPXUO",
    "outputId": "b1e2ba48-a8e3-4d68-a86e-a8240b434965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech/data/lm\n",
      "10 unique words read from vocabulary file.\n",
      "Doesn't look like a character based model.\n",
      "Using detected UTF-8 mode: False\n",
      "Package created in kenlm.scorer\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech/data/lm'\n",
    "! python3 ./generate_package.py --alphabet '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' --lm lm.binary --vocab '/content/drive/My Drive/deepspeech/data/lm/vocab-10.txt' \\\n",
    "  --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58717,
     "status": "ok",
     "timestamp": 1619426580387,
     "user": {
      "displayName": "Badri Narayanan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhjcqRqiLqMGLsp-IpvJRZnBUjAguuaQAbjFsmR6A=s64",
      "userId": "04414803638956108816"
     },
     "user_tz": -330
    },
    "id": "RYmgLUKsPbzs",
    "outputId": "6d6b46df-f121-4900-809a-4d444a8360fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/deepspeech\n",
      "W Due to current feature-cache settings the exact same sample augmentations of the first epoch will be repeated on all following epochs. This could lead to unintended over-fitting. You could use --cache_for_epochs <n_epochs> to invalidate the cache after a given number of epochs.\n",
      "W WARNING: You specified different values for --load_checkpoint_dir and --save_checkpoint_dir, but you are running training and testing in a single invocation. The testing step will respect --load_checkpoint_dir, and thus WILL NOT TEST THE CHECKPOINT CREATED BY THE TRAINING STEP. Train and test in two separate invocations, specifying the correct --load_checkpoint_dir in both cases, or use the same location for loading and saving.\n",
      "I0426 08:42:03.983434 139911501035392 utils.py:157] NumExpr defaulting to 2 threads.\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: beta1_power\n",
      "I Loading variable from checkpoint: beta2_power\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam\n",
      "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam\n",
      "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam\n",
      "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam\n",
      "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam\n",
      "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam\n",
      "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam\n",
      "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam\n",
      "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
      "I Loading variable from checkpoint: learning_rate\n",
      "I Initializing variable: layer_6/bias\n",
      "I Initializing variable: layer_6/bias/Adam\n",
      "I Initializing variable: layer_6/bias/Adam_1\n",
      "I Initializing variable: layer_6/weights\n",
      "I Initializing variable: layer_6/weights/Adam\n",
      "I Initializing variable: layer_6/weights/Adam_1\n",
      "I STARTING Optimization\n",
      "Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 7 | Loss: 182.720398      \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 47.191580       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 21.304411       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 16.934855       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 15.666616       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 14.349271       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 13.453701       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.798211       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 12.222628       \n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 |   Training | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 11.857745       \n",
      "--------------------------------------------------------------------------------\n",
      "I FINISHED optimization in 0:00:38.014866\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: global_step\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "Testing model on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv\n",
      "Test epoch | Steps: 60 | Elapsed Time: 0:00:11                                  \n",
      "Test on /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv - WER: 0.050000, CER: 0.108974, loss: 9.720225\n",
      "--------------------------------------------------------------------------------\n",
      "Best WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.142857, loss: 28.325102\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/11.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம் \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.200000, loss: 24.657740\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/28.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 24.045181\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/31.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 23.825842\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/24.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 19.682833\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/2.wav\n",
      " - src: \"சுழியம்\"\n",
      " - res: \"சுழியம்\"\n",
      "--------------------------------------------------------------------------------\n",
      "Median WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.322342\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/6.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 8.164310\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/23.wav\n",
      " - src: \"ஏழு\"\n",
      " - res: \"ஏழு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.571324\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/12.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.166667, loss: 7.014630\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/9.wav\n",
      " - src: \"நான்கு\"\n",
      " - res: \"நான்கு \"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 6.663801\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/34.wav\n",
      " - src: \"எட்டு\"\n",
      " - res: \"எட்டு\"\n",
      "--------------------------------------------------------------------------------\n",
      "Worst WER: \n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.000000, loss: 1.902744\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/30.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"மூன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 0.000000, CER: 0.250000, loss: 1.564953\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/13.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"ஆறு\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 18.291616\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/43.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 0.333333, loss: 14.654125\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/42.wav\n",
      " - src: \"மூன்று\"\n",
      " - res: \"ஒன்று\"\n",
      "--------------------------------------------------------------------------------\n",
      "WER: 1.000000, CER: 1.000000, loss: 6.909764\n",
      " - wav: file:///content/drive/My Drive/deepspeech/data/TransferLearning/AudioFiles/Speaker3/18.wav\n",
      " - src: \"ஆறு \"\n",
      " - res: \"\"\n",
      "--------------------------------------------------------------------------------\n",
      "I Exporting the model...\n",
      "I Loading best validating checkpoint from /content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints/best_dev-6090\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
      "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
      "I Loading variable from checkpoint: layer_1/bias\n",
      "I Loading variable from checkpoint: layer_1/weights\n",
      "I Loading variable from checkpoint: layer_2/bias\n",
      "I Loading variable from checkpoint: layer_2/weights\n",
      "I Loading variable from checkpoint: layer_3/bias\n",
      "I Loading variable from checkpoint: layer_3/weights\n",
      "I Loading variable from checkpoint: layer_5/bias\n",
      "I Loading variable from checkpoint: layer_5/weights\n",
      "I Loading variable from checkpoint: layer_6/bias\n",
      "I Loading variable from checkpoint: layer_6/weights\n",
      "I Models exported at /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/SpecAugmentExport\n",
      "I Model metadata file saved to /content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/SpecAugmentExport/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/deepspeech'\n",
    "\n",
    "! python3 DeepSpeech.py \\\n",
    "    --drop_source_layers 1 \\\n",
    "    --alphabet_config_path '/content/drive/My Drive/deepspeech/data/tamilalphabet.txt' \\\n",
    "    --save_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/SpecAugmentCheckpoints' \\\n",
    "    --load_checkpoint_dir '/content/drive/MyDrive/deepspeech/data/CommonVoiceTamilAndOpenSLR/Checkpoints' \\\n",
    "    --test_output_file '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/SpecAugmentOutput/output.json' \\\n",
    "    --feature_cache '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/SpecAugmentFeatureCache/feature_cache_' \\\n",
    "    --scorer '/content/drive/My Drive/deepspeech/data/lm/kenlm.scorer' \\\n",
    "    --train_files   '/content/drive/MyDrive/deepspeech/data/TransferLearning/TransferLearningTrain.csv' \\\n",
    "    --test_files  '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3.csv' \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --train_batch_size 64 \\\n",
    "    --test_batch_size 1 \\\n",
    "    --export_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/SpecAugmentExport' \\\n",
    "    --summary_dir '/content/drive/MyDrive/deepspeech/data/TransferLearning/Speaker3/SpecAugmentSummary' \\\n",
    "    --n_hidden 1024 \\\n",
    "    --dropout_rate 0.4 \\\n",
    "    --epochs 10 \\\n",
    "    --augment pitch[p=0.1,pitch=1~0.2] \\\n",
    "    --augment tempo[p=0.1,factor=1~0.5] "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM1NNSh5shTAEXDsm3rd5BO",
   "collapsed_sections": [
    "cKqnStE6ccH9",
    "2-yrhq5_cG1O",
    "enbBD3yOcNIq",
    "qjPX5FG-cSBt"
   ],
   "name": "CommonVoiceTrainPlusOpenSLR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
